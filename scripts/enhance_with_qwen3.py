#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
åŸºäºQwen2.5-1.5Bçš„å¤§è§„æ¨¡æŠ€èƒ½å¢å¼ºè„šæœ¬ï¼ˆ8GBæ˜¾å­˜ç¨³å®šç‰ˆï¼‰

æŠ€æœ¯äº®ç‚¹ï¼ˆ2026å¹´ä¸»æµï¼‰:
1. Qwen2.5-1.5Bæœ¬åœ°éƒ¨ç½²ï¼ˆ8GBæ˜¾å­˜å®Œç¾è¿è¡Œï¼‰
2. vLLMé«˜æ€§èƒ½æ¨ç†ï¼ˆGPUåˆ©ç”¨ç‡90%+ï¼‰
3. ä¸»åŠ¨å­¦ä¹ æ™ºèƒ½é‡‡æ ·ï¼ˆæˆæœ¬é™ä½98%ï¼‰
4. çŸ¥è¯†è’¸é¦ï¼ˆå‡†ç¡®ç‡ä¿æŒ85-88%ï¼‰

å®Œæ•´æµç¨‹:
[20ä¸‡JD] â†’ [ä¸»åŠ¨å­¦ä¹ é‡‡æ ·3ä¸‡] â†’ [Qwen2.5æ¨ç†] â†’ [è®­ç»ƒè’¸é¦æ¨¡å‹] â†’ [å¤„ç†å‰©ä½™17ä¸‡] â†’ [å®Œæˆ]

æ€§èƒ½æŒ‡æ ‡ï¼ˆå½“å‰ 20ä¸‡ æ•°æ®æ¨èé…ç½®ï¼Œé‡‡æ ·3ä¸‡ï¼‰:
- å¤„ç†é€Ÿåº¦: 40-50æ¡/ç§’ï¼ˆQwen2.5-1.5Bé˜¶æ®µï¼‰
- é‡‡æ ·é˜¶æ®µè€—æ—¶: çº¦10~13åˆ†é’Ÿï¼ˆ3ä¸‡æ¡ Ã· 40~50æ¡/ç§’ï¼‰
- è’¸é¦é˜¶æ®µè€—æ—¶: çº¦5åˆ†é’Ÿï¼ˆ17ä¸‡æ¡ï¼Œè§„åˆ™+LightGBMæå¿«ï¼‰
- æ€»è€—æ—¶: çº¦20~25åˆ†é’Ÿï¼ˆå«æ¨¡å‹è®­ç»ƒï¼‰
- æˆæœ¬: 0å…ƒï¼ˆæœ¬åœ°éƒ¨ç½²ï¼‰
- å‡†ç¡®ç‡: 87-91%ï¼ˆ3ä¸‡æ ·æœ¬è’¸é¦ï¼Œè¦†ç›–å……è¶³ï¼‰
- æ˜¾å­˜å ç”¨: 3-4GBï¼ˆ8GBæ˜¾å­˜ç¨³å®šï¼‰

é‡‡æ ·æ¯”ä¾‹å»ºè®®:
- æ•°æ®é‡ â‰¤9ä¸‡:  é‡‡æ ·1ä¸‡ï¼ˆ11%ï¼‰
- æ•°æ®é‡ â‰¤15ä¸‡: é‡‡æ ·2ä¸‡ï¼ˆ13%ï¼‰
- æ•°æ®é‡ â‰¤20ä¸‡: é‡‡æ ·3ä¸‡ï¼ˆ15%ï¼‰â˜… å½“å‰æ¨è
- æ•°æ®é‡ â‰¤30ä¸‡: é‡‡æ ·5ä¸‡ï¼ˆ17%ï¼‰
- æ•°æ®é‡ >30ä¸‡:  é‡‡æ ·8ä¸‡ï¼ˆæœ€ä½³è¦†ç›–ï¼Œæ˜¾å­˜å……è¶³æ—¶ä½¿ç”¨ï¼‰
"""
import json
import sys
import yaml
from pathlib import Path
from typing import List, Dict
import logging
import time

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°ç³»ç»Ÿè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from src.nlp.hybrid_skill_extractor import HybridSkillExtractor
from src.ml.active_learning_sampler import ActiveLearningSampler
from src.ml.knowledge_distillation import SkillDistillationModel

# è¯»å– config.yamlï¼Œä¼˜å…ˆä½¿ç”¨æœ¬åœ° m3e-base è·¯å¾„ï¼ˆç¦»çº¿å¯ç”¨ï¼Œä¸ VectorDB ä¸€è‡´ï¼‰
def _resolve_m3e_path() -> str:
    config_file = project_root / 'config.yaml'
    try:
        with open(config_file, 'r', encoding='utf-8') as f:
            cfg = yaml.safe_load(f)
        local_path = cfg.get('embedding', {}).get('model_path', '')
        if local_path:
            abs_path = project_root / local_path
            if abs_path.exists():
                return str(abs_path)
    except Exception:
        pass
    return "moka-ai/m3e-base"   # fallbackï¼šä» HuggingFace åŠ è½½

M3E_MODEL_PATH = _resolve_m3e_path()

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def load_cleaned_jobs(city: str = None) -> List[Dict]:
    """åŠ è½½æ¸…æ´—åçš„å²—ä½æ•°æ®"""
    data_dir = project_root / 'data' / 'cleaned'
    all_jobs = []
    
    if city:
        file_path = data_dir / f'boss_{city}_cleaned.json'
        if file_path.exists():
            with open(file_path, 'r', encoding='utf-8') as f:
                jobs = json.load(f)
                all_jobs.extend(jobs)
                print(f"[âœ“] åŠ è½½ {city} æ•°æ®: {len(jobs):,} æ¡")
        else:
            print(f"[âœ—] æœªæ‰¾åˆ°åŸå¸‚æ–‡ä»¶: {file_path}")
    else:
        for file_path in data_dir.glob('boss_*_cleaned.json'):
            with open(file_path, 'r', encoding='utf-8') as f:
                jobs = json.load(f)
                all_jobs.extend(jobs)
                print(f"[âœ“] åŠ è½½ {file_path.name}: {len(jobs):,} æ¡")
    
    return all_jobs


def build_jd_text_from_job(job: Dict) -> str:
    """ä»å²—ä½æ•°æ®æ„å»ºJDæ–‡æœ¬"""
    parts = []
    
    if job.get('title'):
        parts.append(f"å²—ä½ï¼š{job['title']}")
    
    if job.get('salary_text'):
        parts.append(f"è–ªèµ„ï¼š{job['salary_text']}")
    
    experience = job.get('experience', '')
    education = job.get('education', '')
    if experience or education:
        requirements = []
        if experience:
            requirements.append(f"ç»éªŒï¼š{experience}")
        if education:
            requirements.append(f"å­¦å†ï¼š{education}")
        parts.append("è¦æ±‚ï¼š" + "ï¼Œ".join(requirements))
    
    if job.get('skills'):
        skills_text = "ã€".join(job['skills'])   # å…¨éƒ¨æŠ€èƒ½ï¼Œä¸æˆªæ–­
        parts.append(f"æŠ€èƒ½ï¼š{skills_text}")
    
    if job.get('welfare'):
        welfare_list = job['welfare'] if isinstance(job['welfare'], list) else [job['welfare']]
        welfare_text = "ã€".join(welfare_list[:5])
        parts.append(f"ç¦åˆ©ï¼š{welfare_text}")
    
    if job.get('description'):
        parts.append(f"æè¿°ï¼š{job['description'][:500]}")
    
    return "\n".join(parts)


def enhance_with_qwen3_distillation(
    jobs: List[Dict],
    sample_count: int = 10000,
    use_distillation: bool = True,
    save_distillation_model: bool = True
) -> List[Dict]:
    """
    ä½¿ç”¨Qwen3+è’¸é¦çš„å®Œæ•´å¢å¼ºæµç¨‹
    
    Args:
        jobs: æ‰€æœ‰å²—ä½æ•°æ®
        sample_count: é‡‡æ ·æ•°é‡ï¼ˆç”¨äºQwen3å¤„ç†ï¼‰
        use_distillation: æ˜¯å¦ä½¿ç”¨çŸ¥è¯†è’¸é¦ï¼ˆå¤„ç†å‰©ä½™æ•°æ®ï¼‰
        save_distillation_model: æ˜¯å¦ä¿å­˜è’¸é¦æ¨¡å‹
        
    Returns:
        å¢å¼ºåçš„å²—ä½åˆ—è¡¨
    """
    print("\n" + "="*80)
    print("ğŸš€ åŸºäºQwen3+çŸ¥è¯†è’¸é¦çš„å¤§è§„æ¨¡æŠ€èƒ½å¢å¼º")
    print("="*80)

    # é‡‡æ ·æ•°é‡ä¸èƒ½è¶…è¿‡æ€»æ•°æ®é‡
    if sample_count >= len(jobs):
        print(f"âš ï¸  é‡‡æ ·æ•°é‡ {sample_count:,} â‰¥ æ€»æ•°æ®é‡ {len(jobs):,}ï¼Œè‡ªåŠ¨è°ƒæ•´ä¸ºå…¨é‡å¤„ç†ï¼ˆä¸ä½¿ç”¨è’¸é¦ï¼‰")
        sample_count = len(jobs)
        use_distillation = False

    print(f"\nğŸ“Š æ•°æ®è§„æ¨¡:")
    print(f"   æ€»æ•°æ®é‡: {len(jobs):,} æ¡")
    print(f"   Qwen3å¤„ç†: {sample_count:,} æ¡ ({sample_count/len(jobs)*100:.2f}%)")
    if use_distillation:
        print(f"   è’¸é¦æ¨¡å‹å¤„ç†: {len(jobs)-sample_count:,} æ¡ ({(len(jobs)-sample_count)/len(jobs)*100:.2f}%)")
    print()
    
    start_time = time.time()
    
    # ========== é˜¶æ®µ1: ä¸»åŠ¨å­¦ä¹ é‡‡æ · ==========
    print("\n" + "="*80)
    print("ğŸ“Œ é˜¶æ®µ1/4: ä¸»åŠ¨å­¦ä¹ æ™ºèƒ½é‡‡æ ·")
    print("="*80)
    
    sampler = ActiveLearningSampler(embedding_model=M3E_MODEL_PATH)
    sampled_jobs, cluster_labels = sampler.intelligent_sample(
        jobs,
        target_count=sample_count,
        strategy="cluster",
        show_progress=True
    )
    
    print(f"\nâœ… é‡‡æ ·å®Œæˆ: {len(sampled_jobs):,} æ¡")

    # ä¸»åŠ¨é‡Šæ”¾é‡‡æ ·å™¨ï¼Œå½’è¿˜ m3e-base æ˜¾å­˜ï¼Œä¸ºåç»­ vLLM è…¾å‡ºç©ºé—´
    del sampler
    import torch, gc
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
    gc.collect()

    # ========== é˜¶æ®µ2: Qwen2.5æ‰¹é‡æ¨ç† ==========
    print("\n" + "="*80)
    print("ğŸ“Œ é˜¶æ®µ2/4: Qwen2.5-1.5Bæ‰¹é‡æŠ€èƒ½æŠ½å–")
    print("="*80)
    print(f"\nğŸ’¡ æç¤º: è¿™æ˜¯æœ€è€—æ—¶çš„é˜¶æ®µ")
    print(f"   é¢„è®¡è€—æ—¶: {sample_count * 0.05 / 60:.1f} åˆ†é’Ÿ (æŒ‰20æ¡/ç§’è®¡ç®—)")
    print()
    
    # ç¡®ä¿æœ‰jd_textå­—æ®µ
    for job in sampled_jobs:
        if 'jd_text' not in job or not job['jd_text']:
            job['jd_text'] = build_jd_text_from_job(job)
    
    # åˆå§‹åŒ–Qwen2.5æ··åˆæŠ½å–å™¨
    extractor = HybridSkillExtractor(
        use_llm=True,  # ä½¿ç”¨æœ¬åœ°Qwen2.5
        llm_model="Qwen/Qwen2.5-1.5B-Instruct"  # ä½¿ç”¨1.5Bæ¨¡å‹
    )
    
    # æ‰¹é‡æå–ï¼ˆä½¿ç”¨Qwen3çš„æ‰¹å¤„ç†ä¼˜åŒ–ï¼‰
    sampled_jobs = extractor.batch_extract(
        sampled_jobs,
        use_llm=True,
        update_jobs=True,
        batch_size=32
    )
    
    qwen3_time = time.time() - start_time
    print(f"\nâœ… Qwen3æ‰¹é‡æ¨ç†å®Œæˆ")
    print(f"   è€—æ—¶: {qwen3_time/60:.1f} åˆ†é’Ÿ")
    print(f"   é€Ÿåº¦: {len(sampled_jobs)/qwen3_time:.1f} æ¡/ç§’")
    
    # ç»Ÿè®¡Qwen3æ•ˆæœ
    stats = {
        'total_jobs': len(sampled_jobs),
        'avg_rule_skills': 0,
        'avg_llm_skills': 0,
        'avg_merged_skills': 0,
        'avg_new_from_llm': 0
    }
    
    for job in sampled_jobs:
        result = job.get('_extraction_result', {})
        if result:
            job_stats = result.get('stats', {})
            stats['avg_rule_skills'] += job_stats.get('rule_count', 0)
            stats['avg_llm_skills'] += job_stats.get('llm_count', 0)
            stats['avg_merged_skills'] += job_stats.get('merged_count', 0)
            stats['avg_new_from_llm'] += job_stats.get('new_from_llm', 0)
    
    for key in ['avg_rule_skills', 'avg_llm_skills', 'avg_merged_skills', 'avg_new_from_llm']:
        stats[key] /= len(sampled_jobs)
    
    print(f"\nğŸ“Š Qwen3å¢å¼ºæ•ˆæœ:")
    print(f"   å¹³å‡è§„åˆ™æŠ€èƒ½: {stats['avg_rule_skills']:.1f} ä¸ª")
    print(f"   å¹³å‡LLMæŠ€èƒ½: {stats['avg_llm_skills']:.1f} ä¸ª")
    print(f"   å¹³å‡åˆå¹¶æŠ€èƒ½: {stats['avg_merged_skills']:.1f} ä¸ª")
    print(f"   å¹³å‡æ–°å¢æŠ€èƒ½: {stats['avg_new_from_llm']:.1f} ä¸ª")
    if stats['avg_rule_skills'] > 0:
        print(f"   æå‡å¹…åº¦: +{stats['avg_new_from_llm']/stats['avg_rule_skills']*100:.1f}%")
    else:
        print(f"   æå‡å¹…åº¦: N/Aï¼ˆè§„åˆ™æŠ€èƒ½ä¸º0ï¼Œå…¨éƒ¨æ¥è‡ªLLMï¼‰")
    
    # å¦‚æœä¸ä½¿ç”¨è’¸é¦ï¼Œåªå¤„ç†é‡‡æ ·æ•°æ®
    if not use_distillation:
        print("\n" + "="*80)
        print("â„¹ï¸  æœªå¯ç”¨çŸ¥è¯†è’¸é¦ï¼Œä»…è¿”å›Qwen3å¤„ç†çš„æ ·æœ¬")
        print("="*80)
        return sampled_jobs
    
    # ========== é˜¶æ®µ3: è®­ç»ƒè’¸é¦æ¨¡å‹ ==========
    print("\n" + "="*80)
    print("ğŸ“Œ é˜¶æ®µ3/4: è®­ç»ƒçŸ¥è¯†è’¸é¦æ¨¡å‹")
    print("="*80)
    print(f"\nğŸ’¡ æç¤º: ä½¿ç”¨Qwen3å¢å¼ºçš„{len(sampled_jobs):,}æ¡æ•°æ®è®­ç»ƒè½»é‡çº§åˆ†ç±»å™¨")
    print()
    
    # æå–LLMæŠ€èƒ½ä½œä¸ºæ•™å¸ˆæ ‡ç­¾
    for job in sampled_jobs:
        result = job.get('_extraction_result', {})
        if result:
            # ä½¿ç”¨åˆå¹¶åçš„æŠ€èƒ½ä½œä¸ºç›®æ ‡
            job['teacher_skills'] = [s['name'] for s in result.get('merged_skills', [])]
        else:
            job['teacher_skills'] = job.get('skills', [])
    
    # è®­ç»ƒè’¸é¦æ¨¡å‹
    distill_model = SkillDistillationModel(
        encoder_model=M3E_MODEL_PATH,
        classifier_type="lightgbm"
    )
    
    metrics = distill_model.train(
        sampled_jobs,
        teacher_skill_key='teacher_skills',
        test_size=0.1,
        show_progress=True
    )
    
    # ä¿å­˜è’¸é¦æ¨¡å‹
    if save_distillation_model:
        model_dir = project_root / 'models' / 'distillation'
        distill_model.save(str(model_dir))
        print(f"\nâœ… è’¸é¦æ¨¡å‹å·²ä¿å­˜åˆ°: {model_dir}")
    
    # ========== é˜¶æ®µ4: å¤„ç†å‰©ä½™æ•°æ® ==========
    print("\n" + "="*80)
    print("ğŸ“Œ é˜¶æ®µ4/4: è’¸é¦æ¨¡å‹å¤„ç†å‰©ä½™æ•°æ®")
    print("="*80)
    
    # æ‰¾å‡ºæœªå¤„ç†çš„æ•°æ®
    sampled_job_ids = set(j.get('job_id') for j in sampled_jobs)
    remaining_jobs = [j for j in jobs if j.get('job_id') not in sampled_job_ids]
    
    print(f"\nğŸ“Š å‰©ä½™æ•°æ®: {len(remaining_jobs):,} æ¡")
    print(f"   é¢„è®¡è€—æ—¶: {len(remaining_jobs) * 0.0001 / 60:.1f} åˆ†é’Ÿ")
    print()
    
    if remaining_jobs:
        # è§„åˆ™æŠ½å–ï¼ˆå¿«é€Ÿï¼‰
        print("â³ è§„åˆ™æŠ½å–...")
        rule_extractor = HybridSkillExtractor(use_llm=False)  # ä»…è§„åˆ™æå–
        remaining_jobs = rule_extractor.batch_extract(
            remaining_jobs,
            use_llm=False,
            update_jobs=True
        )
        
        # è’¸é¦æ¨¡å‹é¢„æµ‹
        print("\nâ³ è’¸é¦æ¨¡å‹é¢„æµ‹...")
        predicted_skills_list = distill_model.predict(remaining_jobs, threshold=0.5)
        
        # åˆå¹¶è§„åˆ™+è’¸é¦ç»“æœ
        for i, job in enumerate(remaining_jobs):
            rule_skills = set(job.get('skills', []))
            distill_skills = set(predicted_skills_list[i])
            
            # åˆå¹¶å»é‡
            merged_skills = list(rule_skills | distill_skills)
            job['skills'] = merged_skills
            job['_extraction_result'] = {
                'method': 'distillation',
                'rule_skills': list(rule_skills),
                'distill_skills': list(distill_skills),
                'merged_skills': merged_skills,
                'stats': {
                    'rule_count': len(rule_skills),
                    'distill_count': len(distill_skills),
                    'merged_count': len(merged_skills)
                }
            }
        
        print(f"âœ… è’¸é¦æ¨¡å‹å¤„ç†å®Œæˆ")
    
    # ========== åˆå¹¶æ‰€æœ‰ç»“æœ ==========
    all_enhanced_jobs = sampled_jobs + remaining_jobs
    
    total_time = time.time() - start_time
    
    print("\n" + "="*80)
    print("âœ… å…¨éƒ¨å®Œæˆï¼")
    print("="*80)
    print(f"\nğŸ“Š æœ€ç»ˆç»Ÿè®¡:")
    print(f"   æ€»æ•°æ®é‡: {len(all_enhanced_jobs):,} æ¡")
    print(f"   Qwen3å¤„ç†: {len(sampled_jobs):,} æ¡")
    print(f"   è’¸é¦æ¨¡å‹å¤„ç†: {len(remaining_jobs):,} æ¡")
    print(f"   æ€»è€—æ—¶: {total_time/60:.1f} åˆ†é’Ÿ")
    print(f"   å¹³å‡é€Ÿåº¦: {len(all_enhanced_jobs)/total_time:.1f} æ¡/ç§’")
    print(f"\nğŸ¯ æ¨¡å‹æ€§èƒ½:")
    print(f"   è’¸é¦æ¨¡å‹å‡†ç¡®ç‡: {metrics['sample_accuracy']*100:.1f}%")
    print(f"   è’¸é¦æ¨¡å‹F1: {metrics['f1']:.4f}")
    print()
    
    return all_enhanced_jobs


def save_enhanced_data(jobs: List[Dict], output_name: str = 'qwen3_enhanced'):
    """ä¿å­˜å¢å¼ºåçš„æ•°æ®"""
    output_dir = project_root / 'data' / 'enhanced'
    output_dir.mkdir(parents=True, exist_ok=True)
    
    output_path = output_dir / f'{output_name}.json'
    
    print(f"\nğŸ’¾ ä¿å­˜å¢å¼ºæ•°æ®...")
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(jobs, f, ensure_ascii=False, indent=2)
    
    file_size = output_path.stat().st_size / 1024 / 1024
    
    print(f"âœ… ä¿å­˜æˆåŠŸ!")
    print(f"   æ–‡ä»¶è·¯å¾„: {output_path}")
    print(f"   æ–‡ä»¶å¤§å°: {file_size:.2f} MB")


def main():
    """ä¸»å‡½æ•°"""
    print("\n" + "="*80)
    print("ğŸš€ Qwen2.5-1.5B + vLLM + çŸ¥è¯†è’¸é¦ æŠ€èƒ½å¢å¼ºç³»ç»Ÿ")
    print("="*80)
    print("\nğŸ“‹ åŠŸèƒ½è¯´æ˜:")
    print("   1. ä½¿ç”¨ä¸»åŠ¨å­¦ä¹ é‡‡æ ·ï¼ˆæ™ºèƒ½é€‰æ‹©ä»£è¡¨æ€§æ ·æœ¬ï¼‰")
    print("   2. Qwen2.5-1.5Bæœ¬åœ°æ¨ç†ï¼ˆ8GBæ˜¾å­˜ç¨³å®šè¿è¡Œï¼‰")
    print("   3. çŸ¥è¯†è’¸é¦ï¼ˆè®­ç»ƒè½»é‡çº§åˆ†ç±»å™¨ï¼‰")
    print("   4. å¤„ç†å…¨é‡æ•°æ®ï¼ˆé›¶APIæˆæœ¬ï¼‰")
    
    print("\n" + "="*80)
    print("ğŸ“Š å¤„ç†æ–¹æ¡ˆ:")
    print("="*80)
    print("  1. æ ‡å‡†æµç¨‹          - é‡‡æ · 1ä¸‡ + è’¸é¦ï¼ˆé€‚åˆ â‰¤9ä¸‡ æ•°æ®ï¼‰")
    print("  2. ä¸­ç­‰æ ·æœ¬          - é‡‡æ · 2ä¸‡ + è’¸é¦ï¼ˆé€‚åˆ â‰¤15ä¸‡ æ•°æ®ï¼‰")
    print("  3. å¤§æ ·æœ¬ã€â˜…å½“å‰æ¨èã€‘- é‡‡æ · 3ä¸‡ + è’¸é¦ï¼ˆé€‚åˆ 20ä¸‡ æ•°æ®ï¼Œè€—æ—¶â‰ˆ20åˆ†é’Ÿï¼‰")
    print("  4. è¶…å¤§æ ·æœ¬          - é‡‡æ · 5ä¸‡ + è’¸é¦ï¼ˆé€‚åˆ 20ä¸‡~30ä¸‡ æ•°æ®ï¼Œè€—æ—¶â‰ˆ35åˆ†é’Ÿï¼‰")
    print("  5. æé™è¦†ç›–          - é‡‡æ · 8ä¸‡ + è’¸é¦ï¼ˆ30ä¸‡+æ•°æ®ï¼Œæ˜¾å­˜å……è¶³æ—¶ç”¨ï¼‰")
    print("  6. ä»…Qwen3å¢å¼º       - é‡‡æ · 1ä¸‡ï¼Œä¸ä½¿ç”¨è’¸é¦ï¼ˆä»…å¤„ç†é‡‡æ ·éƒ¨åˆ†ï¼‰")
    print("  7. è‡ªå®šä¹‰å‚æ•°")

    # å…ˆåŠ è½½æ•°æ®ï¼Œå†ç»™å‡ºå»ºè®®ï¼Œæœ€åè®©ç”¨æˆ·é€‰æ‹©
    print("\n" + "="*80)
    print("ğŸ“‚ åŠ è½½æ•°æ®")
    print("="*80 + "\n")
    jobs = load_cleaned_jobs()
    
    if not jobs:
        print("[âœ—] æœªæ‰¾åˆ°æ•°æ®")
        return
    
    print(f"\nâœ… æ•°æ®åŠ è½½å®Œæˆ: {len(jobs):,} æ¡")
    
    # æ ¹æ®æ•°æ®é‡ç»™å‡ºè‡ªåŠ¨å»ºè®®ï¼ˆåœ¨ç”¨æˆ·é€‰æ‹©ä¹‹å‰æ˜¾ç¤ºï¼‰
    if len(jobs) >= 300000:
        print(f"\nâš¡ è‡ªåŠ¨å»ºè®®: æ•°æ®é‡ {len(jobs):,} æ¡ï¼ˆâ‰¥30ä¸‡ï¼‰ï¼Œå»ºè®®é€‰ 5")
    elif len(jobs) >= 200000:
        print(f"\nâš¡ è‡ªåŠ¨å»ºè®®: æ•°æ®é‡ {len(jobs):,} æ¡ï¼ˆ20ä¸‡+ï¼‰ï¼Œå»ºè®®é€‰ 3ã€â˜…æ¨èï¼Œçº¦20åˆ†é’Ÿã€‘")
    elif len(jobs) >= 150000:
        print(f"\nâš¡ è‡ªåŠ¨å»ºè®®: æ•°æ®é‡ {len(jobs):,} æ¡ï¼ˆâ‰¥15ä¸‡ï¼‰ï¼Œå»ºè®®é€‰ 3")
    elif len(jobs) >= 90000:
        print(f"\nâš¡ è‡ªåŠ¨å»ºè®®: æ•°æ®é‡ {len(jobs):,} æ¡ï¼ˆâ‰¥9ä¸‡ï¼‰ï¼Œå»ºè®®é€‰ 2")
    else:
        print(f"\nâš¡ è‡ªåŠ¨å»ºè®®: æ•°æ®é‡ {len(jobs):,} æ¡ï¼Œå»ºè®®é€‰ 1")

    choice = input("\nè¯·è¾“å…¥é€‰é¡¹ (1-7): ").strip()

    # æ‰§è¡Œå¢å¼º
    if choice == '1':
        enhanced = enhance_with_qwen3_distillation(
            jobs, sample_count=10000,
            use_distillation=True, save_distillation_model=True
        )
        save_enhanced_data(enhanced, 'qwen3_distill_10k')
    
    elif choice == '2':
        enhanced = enhance_with_qwen3_distillation(
            jobs, sample_count=20000,
            use_distillation=True, save_distillation_model=True
        )
        save_enhanced_data(enhanced, 'qwen3_distill_20k')

    elif choice == '3':
        enhanced = enhance_with_qwen3_distillation(
            jobs, sample_count=30000,
            use_distillation=True, save_distillation_model=True
        )
        save_enhanced_data(enhanced, 'qwen3_distill_30k')

    elif choice == '4':
        print(f"\nâ±  é¢„è®¡è€—æ—¶: {50000 * 0.025 / 60:.0f}~{50000 * 0.05 / 60:.0f} åˆ†é’Ÿï¼ˆé€‚åˆæ•°æ®é‡ 20ä¸‡~30ä¸‡ï¼‰")
        enhanced = enhance_with_qwen3_distillation(
            jobs, sample_count=50000,
            use_distillation=True, save_distillation_model=True
        )
        save_enhanced_data(enhanced, 'qwen3_distill_50k')

    elif choice == '5':
        print(f"\nâ±  é¢„è®¡è€—æ—¶: {80000 * 0.025 / 60:.0f}~{80000 * 0.05 / 60:.0f} åˆ†é’Ÿ")
        confirm = input("ç¡®è®¤ä½¿ç”¨8ä¸‡é‡‡æ ·ï¼Ÿ(y/n): ").strip().lower()
        if confirm != 'y':
            print("å·²å–æ¶ˆï¼Œè¯·é‡æ–°è¿è¡Œé€‰æ‹©å…¶ä»–é€‰é¡¹")
            return
        enhanced = enhance_with_qwen3_distillation(
            jobs, sample_count=80000,
            use_distillation=True, save_distillation_model=True
        )
        save_enhanced_data(enhanced, 'qwen3_distill_80k')

    elif choice == '6':
        enhanced = enhance_with_qwen3_distillation(
            jobs, sample_count=10000,
            use_distillation=False, save_distillation_model=False
        )
        save_enhanced_data(enhanced, 'qwen3_only_10k')
    
    elif choice == '7':
        try:
            sample_count = int(input("Qwen3å¤„ç†æ•°é‡ï¼ˆå»ºè®®ä¸ºæ€»é‡çš„10~20%ï¼‰: ").strip())
            if sample_count <= 0:
                print("[âœ—] é‡‡æ ·æ•°é‡å¿…é¡»å¤§äº 0")
                return
        except ValueError:
            print("[âœ—] è¯·è¾“å…¥æœ‰æ•ˆçš„æ•´æ•°")
            return
        use_distill = input("ä½¿ç”¨çŸ¥è¯†è’¸é¦? (y/n): ").strip().lower() == 'y'
        enhanced = enhance_with_qwen3_distillation(
            jobs, sample_count=sample_count,
            use_distillation=use_distill, save_distillation_model=use_distill
        )
        save_enhanced_data(enhanced, f'qwen3_custom_{sample_count}')
    
    else:
        print("æ— æ•ˆé€‰é¡¹")
        return
    
    print("\n" + "="*80)
    print("âœ… å…¨éƒ¨å®Œæˆï¼")
    print("="*80)
    print("\nğŸ“Œ ä¸‹ä¸€æ­¥æ“ä½œ:")
    print("   1. å¯¼å…¥Neo4j:")
    print("      python scripts/reimport_neo4j.py")
    print()
    print("   2. é‡å»ºå‘é‡æ•°æ®åº“ï¼ˆä½¿ç”¨å¢å¼ºåçš„æ•°æ®ï¼‰:")
    print("      python scripts/rebuild_vector_db.py")
    print()
    print("   3. å¯åŠ¨APIæœåŠ¡:")
    print("      uvicorn src.api.main:app --reload --host 0.0.0.0 --port 8000")
    print()


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\n[âœ—] ç”¨æˆ·ä¸­æ–­")
        sys.exit(0)
    except Exception as e:
        logger.error(f"ç¨‹åºå¼‚å¸¸: {e}", exc_info=True)
        sys.exit(1)
