# ğŸš€ å¿«é€Ÿå¼€å§‹æŒ‡å—ï¼ˆQwen3ç‰ˆ - 2026å¹´2æœˆï¼‰

> **ç›®æ ‡**: 30åˆ†é’Ÿå¿«é€Ÿä½“éªŒQwen3æœ¬åœ°éƒ¨ç½²+æŠ€èƒ½æŠ½å–

---

## âš¡ æœ€å¿«è·¯å¾„ï¼ˆ10åˆ†é’Ÿä½“éªŒï¼‰

### å‰ç½®æ¡ä»¶

- âœ… NVIDIA GPU (12GB+ æ˜¾å­˜)
- âœ… Python 3.9+

### å¿«é€Ÿå®‰è£…

```bash
# 1. å®‰è£…æ ¸å¿ƒä¾èµ–
pip install torch vllm sentence-transformers scikit-learn lightgbm

# 2. å…‹éš†é¡¹ç›®
git clone <your-repo-url>
cd skill-graph-recruit

# 3. æµ‹è¯•Qwen3
python src/llm/qwen3_local_client.py
```

**é¦–æ¬¡è¿è¡Œä¼šè‡ªåŠ¨ä¸‹è½½Qwen3æ¨¡å‹ï¼ˆçº¦13GBï¼‰ï¼Œéœ€è¦5-10åˆ†é’Ÿ**

---

## ğŸ“‹ å®Œæ•´æ­¥éª¤ï¼ˆ30åˆ†é’Ÿï¼‰

### Step 1: ç¯å¢ƒå‡†å¤‡ï¼ˆ10åˆ†é’Ÿï¼‰

#### 1.1 åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ

```bash
# ä½¿ç”¨condaï¼ˆæ¨èï¼‰
conda create -n skill-graph python=3.10
conda activate skill-graph

# æˆ–ä½¿ç”¨venv
python -m venv venv
source venv/bin/activate  # Linux/Mac
venv\Scripts\activate     # Windows
```

#### 1.2 å®‰è£…PyTorchï¼ˆGPUç‰ˆæœ¬ï¼‰

```bash
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

#### 1.3 å®‰è£…vLLM

```bash
pip install vllm
```

#### 1.4 å®‰è£…å…¶ä»–ä¾èµ–

```bash
pip install -r requirements.txt
```

#### 1.5 éªŒè¯ç¯å¢ƒ

```bash
python scripts/check_environment.py
```

**é¢„æœŸè¾“å‡º**:
```
âœ… Pythonç‰ˆæœ¬: 3.10.x
âœ… PyTorchå·²å®‰è£…: 2.0.x
âœ… CUDAå¯ç”¨: True
âœ… GPU: NVIDIA GeForce RTX 4090 (24GB)
âœ… vLLMå·²å®‰è£…: 0.4.x
```

---

### Step 2: æµ‹è¯•Qwen3ï¼ˆ10åˆ†é’Ÿï¼‰

#### 2.1 æµ‹è¯•Qwen3æœ¬åœ°å®¢æˆ·ç«¯

```bash
python src/llm/qwen3_local_client.py
```

**é¦–æ¬¡è¿è¡Œ**:
- è‡ªåŠ¨ä¸‹è½½Qwen3-7Bæ¨¡å‹ï¼ˆçº¦13GBï¼‰
- ä¸‹è½½è·¯å¾„: `~/.cache/huggingface/`
- éœ€è¦5-10åˆ†é’Ÿï¼ˆå–å†³äºç½‘é€Ÿï¼‰

**é¢„æœŸè¾“å‡º**:
```
================================================================================
ğŸš€ åˆå§‹åŒ–Qwen3-7Bæœ¬åœ°æ¨¡å‹
================================================================================
âœ… GPU: NVIDIA GeForce RTX 4090
âœ… æ˜¾å­˜: 24.0 GB
âœ… vLLMå·²å®‰è£…
â³ åŠ è½½æ¨¡å‹: Qwen/Qwen3-7B-Instruct
âœ… æ¨¡å‹åŠ è½½å®Œæˆï¼
================================================================================

ğŸ§ª æµ‹è¯•Qwen3æœ¬åœ°å®¢æˆ·ç«¯
ã€æµ‹è¯•1: å•æ¡æŠ€èƒ½æå–ã€‘
âœ… æå–æŠ€èƒ½: ['Python', 'Django', 'MySQL', 'Redis', 'Docker', 'Kubernetes']
   å…± 6 ä¸ªæŠ€èƒ½

ã€æµ‹è¯•2: æ‰¹é‡æŠ€èƒ½æå–ã€‘
âœ… æ‰¹é‡æå–å®Œæˆ: 10 æ¡
   å¹³å‡æ¯æ¡: 6.5 ä¸ªæŠ€èƒ½

âœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼
```

#### 2.2 æµ‹è¯•ä¸»åŠ¨å­¦ä¹ é‡‡æ ·

```bash
python src/ml/active_learning_sampler.py
```

**é¢„æœŸè¾“å‡º**:
```
ğŸ¯ å¼€å§‹æ™ºèƒ½é‡‡æ ·
æ€»æ•°æ®é‡: 1,000 æ¡
ç›®æ ‡é‡‡æ ·: 100 æ¡ (10.00%)
é‡‡æ ·ç­–ç•¥: cluster

[1/4] æå–JDæ–‡æœ¬...
âœ… æå–å®Œæˆ: 1000 æ¡

[2/4] å‘é‡åŒ–JDæ–‡æœ¬...
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:15<00:00, 66.67it/s]
âœ… å‘é‡åŒ–å®Œæˆ: shape=(1000, 768)

[3/4] K-Meansèšç±»...
âœ… èšç±»å®Œæˆ

âœ… é‡‡æ ·å®Œæˆ: 100 æ¡
```

#### 2.3 æµ‹è¯•æ··åˆæŠ½å–å™¨

```bash
python -c "from src.nlp.hybrid_skill_extractor import HybridSkillExtractor; print('âœ… æ··åˆæŠ½å–å™¨å¯¼å…¥æˆåŠŸ')"
```

---

### Step 3: è¿è¡Œå®Œæ•´æµç¨‹ï¼ˆ10åˆ†é’Ÿï¼‰

#### 3.1 å‡†å¤‡æ•°æ®

ç¡®ä¿æœ‰æ¸…æ´—åçš„æ•°æ®ï¼š

```bash
ls data/cleaned/
# åº”è¯¥çœ‹åˆ°: boss_åŒ—äº¬_cleaned.json, boss_ä¸Šæµ·_cleaned.json, ...
```

å¦‚æœæ²¡æœ‰æ•°æ®ï¼Œå¯ä»¥ä½¿ç”¨æµ‹è¯•æ•°æ®ï¼š

```bash
python scripts/generate_test_data.py
```

#### 3.2 è¿è¡ŒQwen3å¢å¼ºè„šæœ¬

```bash
python scripts/enhance_with_qwen3.py
```

**äº¤äº’å¼é€‰æ‹©**:

```
ğŸš€ Qwen3-7B + çŸ¥è¯†è’¸é¦ æŠ€èƒ½å¢å¼ºç³»ç»Ÿ
================================================================================

ğŸ“Š å¤„ç†æ–¹æ¡ˆ:
  1. å®Œæ•´æµç¨‹ï¼ˆæ¨èï¼‰ - é‡‡æ ·1ä¸‡ + è’¸é¦å¤„ç†å…¨éƒ¨
  2. å®Œæ•´æµç¨‹ï¼ˆå¤§æ ·æœ¬ï¼‰ - é‡‡æ ·2ä¸‡ + è’¸é¦å¤„ç†å…¨éƒ¨
  3. ä»…Qwen3å¢å¼º - é‡‡æ ·1ä¸‡ï¼Œä¸ä½¿ç”¨è’¸é¦
  4. è‡ªå®šä¹‰å‚æ•°

è¯·è¾“å…¥é€‰é¡¹ (1-4): 3  # é€‰æ‹©3å¿«é€Ÿæµ‹è¯•ï¼ˆä¸ä½¿ç”¨è’¸é¦ï¼‰
```

**é¢„æœŸç»“æœ**:
- ä¸»åŠ¨å­¦ä¹ é‡‡æ ·: 3åˆ†é’Ÿ
- Qwen3æ¨ç†: 8-10åˆ†é’Ÿ
- ä¿å­˜å¢å¼ºæ•°æ®

---

## ğŸ¯ æ ¸å¿ƒåŠŸèƒ½æ¼”ç¤º

### åŠŸèƒ½1: å•æ¡æŠ€èƒ½æŠ½å–

```python
from src.nlp.hybrid_skill_extractor import HybridSkillExtractor

# åˆå§‹åŒ–æŠ½å–å™¨
extractor = HybridSkillExtractor(
    llm_mode="local",  # ä½¿ç”¨æœ¬åœ°Qwen3
    llm_model="Qwen/Qwen3-7B-Instruct"
)

# æŠ½å–æŠ€èƒ½
job = {
    'title': 'Pythonåç«¯å¼€å‘å·¥ç¨‹å¸ˆ',
    'jd_text': 'è´Ÿè´£åç«¯å¼€å‘ï¼Œç†Ÿæ‚‰Pythonã€Djangoã€MySQLã€Redis...'
}

result = extractor.extract(job, use_llm=True)

print("è§„åˆ™æŠ½å–:", result['stats']['rule_count'], "ä¸ª")
print("LLMæŠ½å–:", result['stats']['llm_count'], "ä¸ª")
print("åˆå¹¶å:", result['stats']['merged_count'], "ä¸ª")
print("æ–°å¢:", result['stats']['new_from_llm'], "ä¸ª")
```

### åŠŸèƒ½2: æ‰¹é‡æŠ½å–ï¼ˆé«˜æ€§èƒ½ï¼‰

```python
# æ‰¹é‡å¤„ç†ï¼ˆä½¿ç”¨vLLMæ‰¹å¤„ç†ä¼˜åŒ–ï¼‰
jobs = [...]  # 1000æ¡å²—ä½

enhanced_jobs = extractor.batch_extract(
    jobs,
    use_llm=True,
    batch_size=32  # æ‰¹å¤„ç†å¤§å°
)

print(f"å¤„ç†å®Œæˆ: {len(enhanced_jobs)} æ¡")
```

### åŠŸèƒ½3: ä¸»åŠ¨å­¦ä¹ +è’¸é¦ï¼ˆå®Œæ•´æµç¨‹ï¼‰

```python
from src.ml.active_learning_sampler import ActiveLearningSampler
from src.ml.knowledge_distillation import SkillDistillationModel

# 1. æ™ºèƒ½é‡‡æ ·
sampler = ActiveLearningSampler()
sampled, labels = sampler.intelligent_sample(all_jobs, target_count=10000)

# 2. Qwen3æ¨ç†
extractor = HybridSkillExtractor(llm_mode="local")
enhanced = extractor.batch_extract(sampled, use_llm=True)

# 3. è®­ç»ƒè’¸é¦æ¨¡å‹
distill = SkillDistillationModel()
metrics = distill.train(enhanced, teacher_skill_key='llm_skills')

print(f"è’¸é¦æ¨¡å‹å‡†ç¡®ç‡: {metrics['sample_accuracy']*100:.1f}%")

# 4. å¤„ç†å‰©ä½™æ•°æ®
remaining_jobs = [...]  # å‰©ä½™æ•°æ®
predicted_skills = distill.predict(remaining_jobs)
```

---

## ğŸš€ è¿›é˜¶ä½¿ç”¨

### 1. å¯¼å…¥Neo4j

```bash
# å¯åŠ¨Neo4j
docker run -d --name neo4j \
  -p 7474:7474 -p 7687:7687 \
  -e NEO4J_AUTH=neo4j/password \
  neo4j:latest

# å¯¼å…¥æ•°æ®
python scripts/reimport_neo4j.py
```

### 2. åˆå§‹åŒ–å‘é‡æ•°æ®åº“

```bash
python scripts/init_vector_db.py
```

### 3. å¯åŠ¨APIæœåŠ¡

```bash
cd src/api
uvicorn main:app --reload
```

è®¿é—®: http://localhost:8000/docs

---

## ğŸ’¡ æ€§èƒ½è°ƒä¼˜å»ºè®®

### GPUæ˜¾å­˜ä¸è¶³

```python
# é™ä½æ˜¾å­˜åˆ©ç”¨ç‡
client = Qwen3LocalClient(
    gpu_memory_utilization=0.8  # ä»0.9é™åˆ°0.8
)

# å‡å°æ‰¹å¤„ç†å¤§å°
extractor.batch_extract(
    jobs,
    batch_size=16  # ä»32é™åˆ°16
)
```

### åŠ é€Ÿæ¨ç†

```python
# ä½¿ç”¨FP16ï¼ˆé»˜è®¤å·²å¯ç”¨ï¼‰
client = Qwen3LocalClient(
    dtype="half"  # FP16ï¼Œæ¯”FP32å¿«2å€
)

# å¤šGPUå¹¶è¡Œ
client = Qwen3LocalClient(
    tensor_parallel_size=2  # ä½¿ç”¨2å—GPU
)
```

---

## â“ å¸¸è§é—®é¢˜

### Q1: GPUæ˜¾å­˜ä¸è¶³

**é”™è¯¯**: `OutOfMemoryError: CUDA out of memory`

**è§£å†³**:
```python
# é™ä½GPUæ˜¾å­˜åˆ©ç”¨ç‡
gpu_memory_utilization=0.7  # ä»0.9é™åˆ°0.7
```

### Q2: æ¨¡å‹ä¸‹è½½æ…¢

**è§£å†³**:
```bash
# ä½¿ç”¨HuggingFaceé•œåƒ
export HF_ENDPOINT=https://hf-mirror.com
python src/llm/qwen3_local_client.py
```

### Q3: vLLMå®‰è£…å¤±è´¥

**è§£å†³**:
```bash
# æ–¹æ¡ˆ1: æŒ‡å®šCUDAç‰ˆæœ¬
pip install vllm --extra-index-url https://download.pytorch.org/whl/cu118

# æ–¹æ¡ˆ2: ä»æºç å®‰è£…
pip install git+https://github.com/vllm-project/vllm.git
```

### Q4: æ¨ç†é€Ÿåº¦æ…¢

**æ£€æŸ¥**:
1. GPUåˆ©ç”¨ç‡ï¼ˆnvidia-smiï¼‰
2. æ‰¹å¤„ç†å¤§å°ï¼ˆå¢åŠ åˆ°32æˆ–64ï¼‰
3. æ˜¯å¦ä½¿ç”¨FP16

---

## ğŸ“š ä¸‹ä¸€æ­¥

1. **é˜…è¯»è¯¦ç»†æ–‡æ¡£**: `docs/å®Œæ•´å®æ–½æ­¥éª¤-Qwen3ç‰ˆ.md`
2. **æŸ¥çœ‹æ€§èƒ½æŒ‡æ ‡**: `docs/Qwen3éƒ¨ç½²ä¸ä½¿ç”¨æŒ‡å—.md`
3. **å‡†å¤‡ç®€å†**: `docs/AIåº”ç”¨æ–¹å‘è½¬å‹è§„åˆ’.md`

---

## ğŸ‰ æ­å–œï¼

æ‚¨å·²å®ŒæˆQwen3æœ¬åœ°éƒ¨ç½²å’ŒåŸºç¡€æµ‹è¯•ï¼

**ä¸‹ä¸€æ­¥å»ºè®®**:
- å¤„ç†å®Œæ•´æ•°æ®é›†ï¼ˆ50ä¸‡+ï¼‰
- éƒ¨ç½²APIæœåŠ¡
- å‡†å¤‡é¡¹ç›®Demo

---

**éœ€è¦å¸®åŠ©ï¼Ÿ** æŸ¥çœ‹å®Œæ•´æ–‡æ¡£æˆ–æäº¤Issueï¼

ğŸš€ **ç¥æ‚¨ä½¿ç”¨æ„‰å¿«ï¼**
