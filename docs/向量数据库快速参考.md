# 🚀 向量数据库快速参考卡片

## 📊 您的数据规模

```
├─ 已完成: 9万条（已清洗）
└─ 计划中: 30万条（待抓取）
   总计: ~40万条招聘数据
```

---

## 🎯 两个脚本，何时用哪个？

### 脚本对比

| 场景 | 使用脚本 | 命令 | 说明 |
|------|---------|------|------|
| 🆕 **首次初始化** | `init_vector_db.py` | `python scripts/init_vector_db.py` | 清空并创建 |
| ✅ **添加新数据** | `update_vector_db.py` | `python scripts/update_vector_db.py` | 只添加新的 |
| 🔄 **更换模型** | `init_vector_db.py` | `python scripts/init_vector_db.py --force` | 重建全部 |
| 📝 **修改旧数据** | `update_vector_db.py` | `python scripts/update_vector_db.py --force-update` | 强制更新 |

---

## 💡 您的最佳方案

### 第1次（9万条）- ✅ 已完成

```bash
python scripts/init_vector_db.py
```

**结果**：
```
✅ 向量数据库初始化完成！
  总文档数: 69,205
```

---

### 第2次（30万条）- 🔜 推荐使用

```bash
# 1. 抓取新数据
python src/crawler/boss_listdata.py --city 武汉
python src/crawler/boss_listdata.py --city 西安
# ... 更多城市

# 2. 清洗新数据
python src/data_processing/data_cleaner.py

# 3. （可选）LLM增强
python scripts/enhance_with_qwen3.py

# 4. 增量更新向量数据库 ⭐ 核心步骤
python scripts/update_vector_db.py --source enhanced
```

**预期结果**：
```
✅ 向量数据库更新完成！
  更新前: 69,205 条
  更新后: 369,205 条
  新增: 300,000 条
```

---

## ⚡ 时间对比

| 方案 | 处理数据量 | 耗时 | 推荐度 |
|------|-----------|------|--------|
| 方案A：全量重建 | 40万条 | 约40分钟 | ⭐⭐ |
| 方案B：增量更新 | 30万条（新增） | 约30分钟 | ⭐⭐⭐⭐⭐ |

**节省时间**：约10分钟 ✅

---

## 🔑 关键参数

### `update_vector_db.py` 参数

```bash
# 基础用法（清洗数据）
python scripts/update_vector_db.py

# 使用LLM增强数据
python scripts/update_vector_db.py --source enhanced

# 强制更新已有数据
python scripts/update_vector_db.py --force-update

# 不跳过重复数据
python scripts/update_vector_db.py --no-skip-duplicates
```

---

## ✅ 自动去重机制

**基于 `job_id` 自动去重：**

```python
# 示例
现有数据: job_001, job_002, job_003
新数据: job_003, job_004, job_005

结果:
  跳过: job_003（已存在）
  添加: job_004, job_005
  
最终: job_001, job_002, job_003, job_004, job_005
```

---

## 🎨 工作流程图

```
首次运行（9万条）
┌─────────────────────┐
│ 1. 抓取数据         │
│ 2. 清洗数据         │
│ 3. LLM增强（可选）  │
│ 4. init_vector_db   │ ← 使用首次初始化脚本
└─────────────────────┘
          │
          ✓ 完成
          │
          ▼
后续更新（30万条）
┌─────────────────────┐
│ 1. 抓取新数据       │
│ 2. 清洗新数据       │
│ 3. LLM增强（可选）  │
│ 4. update_vector_db │ ← 使用增量更新脚本 ⭐
└─────────────────────┘
          │
          ✓ 完成
          │
          ▼
      数据库状态
┌─────────────────────┐
│ 总计: 369,205 条    │
│ 旧数据: 69,205 条   │
│ 新数据: 300,000 条  │
└─────────────────────┘
```

---

## 🚨 常见错误

### 错误1：没有新数据

```
✅ 没有新数据需要添加
数据库中已有全部 69,205 条数据
```

**原因**：所有数据已存在  
**解决**：检查是否有新文件，或使用 `--force-update`

---

### 错误2：内存不足

```
MemoryError: Unable to allocate array
```

**解决**：
1. 降低 batch_size（50 → 32）
2. 分批处理数据

---

### 错误3：模型未下载

```
OSError: Can't load model
```

**解决**：
```bash
python scripts/download_m3e_model.py
```

---

## 📞 快速帮助

**问题**：不知道该用哪个脚本？

**决策树**：
```
是首次运行吗？
├─ 是 → init_vector_db.py
└─ 否 → 有新数据吗？
         ├─ 是 → update_vector_db.py ⭐
         └─ 否 → 不需要运行
```

**问题**：增量更新会覆盖旧数据吗？

**回答**：不会！基于 `job_id` 自动去重，已存在的数据会被跳过（除非使用 `--force-update`）。

**问题**：可以同时运行多个更新吗？

**回答**：不推荐。ChromaDB 不支持并发写入，可能导致数据损坏。

---

## 🎯 记住这一句

> **首次用 `init`，后续用 `update`！**

---

**创建时间**：2026年2月11日  
**适用场景**：9万初始数据 + 30万增量数据
