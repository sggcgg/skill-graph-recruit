# ğŸš€ Qwen2.5-1.5B æœ¬åœ°éƒ¨ç½²ä¸ä½¿ç”¨æŒ‡å—ï¼ˆ8GBæ˜¾å­˜ç¨³å®šç‰ˆï¼‰

> **æŠ€æœ¯æ ˆ**: Qwen2.5-1.5B-Instruct + vLLM + ä¸»åŠ¨å­¦ä¹  + çŸ¥è¯†è’¸é¦
> 
> **ç›®æ ‡**: é›¶æˆæœ¬å¤„ç†50ä¸‡æ¡å²—ä½æ•°æ®ï¼Œå‡†ç¡®ç‡85%+  
> **ç¡¬ä»¶**: RTX 4060 8GBæ˜¾å­˜å®Œç¾è¿è¡Œ

---

## ğŸ“‹ ç›®å½•

1. [ä¸ºä»€ä¹ˆé€‰æ‹©Qwen3æœ¬åœ°éƒ¨ç½²](#ä¸ºä»€ä¹ˆé€‰æ‹©qwen3æœ¬åœ°éƒ¨ç½²)
2. [ç¡¬ä»¶è¦æ±‚](#ç¡¬ä»¶è¦æ±‚)
3. [ç¯å¢ƒé…ç½®](#ç¯å¢ƒé…ç½®)
4. [æ¨¡å‹ä¸‹è½½ä¸éƒ¨ç½²](#æ¨¡å‹ä¸‹è½½ä¸éƒ¨ç½²)
5. [ä½¿ç”¨æ–¹æ³•](#ä½¿ç”¨æ–¹æ³•)
6. [æ€§èƒ½ä¼˜åŒ–](#æ€§èƒ½ä¼˜åŒ–)
7. [å¸¸è§é—®é¢˜](#å¸¸è§é—®é¢˜)

---

## ğŸ¯ ä¸ºä»€ä¹ˆé€‰æ‹©Qwen2.5-1.5Bæœ¬åœ°éƒ¨ç½²

### å¯¹æ¯”åˆ†æ

| æ–¹æ¡ˆ | æˆæœ¬ | é€Ÿåº¦ | å‡†ç¡®ç‡ | 8GBæ˜¾å­˜ | 2026ç«äº‰åŠ› |
|------|------|------|--------|---------|-----------|
| **Qwen2.5-1.5B+vLLMï¼ˆæ¨èï¼‰** | 0å…ƒ | 40-50æ¡/ç§’ | 85-88% | âœ… ç¨³å®š | â­â­â­â­â­ |
| Qwen2.5-7B+vLLM | 0å…ƒ | 20-30æ¡/ç§’ | 92% | âŒ OOM | â­â­â­â­â­ |
| DeepSeek APIï¼ˆé”™å³°ï¼‰ | 200å…ƒ/50ä¸‡æ¡ | 1-2æ¡/ç§’ | 92% | N/A | â­â­â­â­ |
| é€šä¹‰åƒé—®API | å…è´¹é¢åº¦ä»…7-8Kæ¡ | 1-2æ¡/ç§’ | 92% | N/A | â­â­â­ |
| çº¯è§„åˆ™åŒ¹é… | 0å…ƒ | 1000æ¡/ç§’ | 75% | N/A | â­â­ |

### Qwen2.5-1.5Bä¼˜åŠ¿

1. **æœ€æ–°æŠ€æœ¯** (2024å¹´9æœˆå‘å¸ƒ)
   - è®­ç»ƒæ•°æ®: 533B tokené«˜è´¨é‡æ•°æ®
   - ä»£ç ç†è§£èƒ½åŠ›å¼ºï¼ŒæŒ‡ä»¤éµå¾ªç²¾å‡†
   - Apache 2.0å¼€æºåè®®

2. **8GBæ˜¾å­˜å®Œç¾é€‚é…**
   - âœ… æ˜¾å­˜å ç”¨ä»…3-4GB
   - âœ… ç•™è¶³ä½™é‡ç»™KV cache
   - âœ… ç¨³å®šè¿è¡Œï¼Œé›¶OOMé£é™©

3. **ç®€å†åŠ åˆ†**
   - âœ… "ä½¿ç”¨Qwen2.5æœ€æ–°æ¨¡å‹æœ¬åœ°éƒ¨ç½²"
   - âœ… "vLLMé«˜æ€§èƒ½æ¨ç†ï¼ŒGPUåˆ©ç”¨ç‡90%+"
   - âœ… "é’ˆå¯¹8GBæ˜¾å­˜ä¼˜åŒ–ï¼Œæ¨¡å‹é€‰å‹èƒ½åŠ›"
   - âœ… "é›¶APIæˆæœ¬ï¼Œå®Œå…¨è‡ªä¸»å¯æ§"

4. **é¢è¯•è¯æœ¯**
   ```
   "æˆ‘çš„é¡¹ç›®åŸºäºQwen2.5-1.5Bæ¨¡å‹ï¼š
   1. æœ€åˆè€ƒè™‘7Bæ¨¡å‹ï¼Œä½†8GBæ˜¾å­˜æ— æ³•æ”¯æŒvLLMçš„KV cacheéœ€æ±‚
   2. ç»è¿‡åˆ†æï¼Œé€‰æ‹©1.5Bæ¨¡å‹ï¼Œæ˜¾å­˜å ç”¨é™åˆ°4GBä»¥ä¸‹
   3. é…åˆvLLMæ‰¹å¤„ç†ä¼˜åŒ–ï¼Œæ¨ç†é€Ÿåº¦è¾¾40æ¡/ç§’ï¼ŒGPUåˆ©ç”¨ç‡90%+
   4. é€šè¿‡ä¸»åŠ¨å­¦ä¹ +çŸ¥è¯†è’¸é¦ï¼Œç”¨1ä¸‡æ ·æœ¬è®­ç»ƒè½»é‡æ¨¡å‹å¤„ç†å‰©ä½™æ•°æ®
   5. æœ€ç»ˆé›¶æˆæœ¬å¤„ç†10ä¸‡+æ•°æ®ï¼Œå‡†ç¡®ç‡ä¿æŒ85%+
   6. è¿™è®©æˆ‘æ·±åˆ»ç†è§£äº†ç¡¬ä»¶çº¦æŸä¸‹çš„æ¨¡å‹é€‰å‹å’Œå·¥ç¨‹ä¼˜åŒ–"
   ```

---

## ğŸ’» ç¡¬ä»¶è¦æ±‚

### æœ€ä½é…ç½®ï¼ˆå¯è¿è¡Œï¼‰

| ç¡¬ä»¶ | è¦æ±‚ | è¯´æ˜ |
|------|------|------|
| **GPU** | NVIDIA RTX 3060 (12GB) | æ˜¾å­˜æ˜¯å…³é”® |
| **CPU** | Intel i5 / AMD Ryzen 5 | 4æ ¸å³å¯ |
| **å†…å­˜** | 16GB | å»ºè®®32GB |
| **ç¡¬ç›˜** | 50GB å¯ç”¨ç©ºé—´ | SSDä¼˜å…ˆ |

### æ¨èé…ç½®ï¼ˆæµç•…ï¼‰

| ç¡¬ä»¶ | è¦æ±‚ | æ€§èƒ½ |
|------|------|------|
| **GPU** | RTX 4060 / 4060 Ti / 4070 | 40-50æ¡/ç§’ |
| **CPU** | Intel i5 / AMD Ryzen 5 | 4æ ¸+ |
| **å†…å­˜** | 16GB | DDR4/DDR5 |
| **ç¡¬ç›˜** | 50GB SSD | NVMe |

### GPUæ¨èï¼ˆQwen2.5-1.5Bï¼‰

| GPUå‹å· | æ˜¾å­˜ | æ¨ç†é€Ÿåº¦ | é€‚é…åº¦ | ä»·æ ¼ï¼ˆçº¦ï¼‰ |
|---------|------|---------|--------|----------|
| **RTX 4060 Laptop** | **8GB** | **40-50æ¡/ç§’** | **âœ… å®Œç¾** | **ç¬”è®°æœ¬** |
| RTX 3060 | 12GB | 50-60æ¡/ç§’ | âœ… å®½è£• | Â¥2000 |
| RTX 4060 Ti | 16GB | 55-65æ¡/ç§’ | âœ… éå¸¸å®½è£• | Â¥3000 |
| RTX 4070 | 12GB | 60-70æ¡/ç§’ | âœ… å®½è£• | Â¥4500 |

> ğŸ’¡ **å»ºè®®**: RTX 4060 8GBå®Œå…¨å¤Ÿç”¨ï¼Œæ— éœ€æ›´è´µçš„æ˜¾å¡ï¼

---

## ğŸ”§ ç¯å¢ƒé…ç½®

### 1. æ£€æŸ¥GPU

```bash
# Windows
nvidia-smi

# Linux/WSL2
nvidia-smi
lspci | grep -i nvidia
```

**è¾“å‡ºç¤ºä¾‹**:
```
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 525.xx.xx    Driver Version: 525.xx.xx    CUDA Version: 12.0  |
|-------------------------------+----------------------+----------------------+
| GPU  Name        TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |
|   0  NVIDIA GeForce RTX 4090  | 00000000:01:00.0 On |                  N/A |
+-------------------------------+----------------------+----------------------+
```

### 2. åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ

#### Windows WSL2ç”¨æˆ·ï¼ˆæ¨èï¼‰

**âš ï¸ é‡è¦**: vLLMåªæ”¯æŒLinuxç¯å¢ƒï¼ŒWindowsç”¨æˆ·å¿…é¡»ä½¿ç”¨WSL2ã€‚

**æœ€ä½³å®è·µï¼šä»£ç åœ¨Windowsï¼Œè™šæ‹Ÿç¯å¢ƒåœ¨WSLæœ¬åœ°**

```bash
# 1. è¿›å…¥é¡¹ç›®ç›®å½•ï¼ˆè®¿é—®Windowsçš„Dç›˜ï¼‰
cd /mnt/d/PycharmProjects/skill-graph-recruit

# 2. åœ¨WSLä¸»ç›®å½•åˆ›å»ºè™šæ‹Ÿç¯å¢ƒï¼ˆé¿å…æƒé™é—®é¢˜ï¼‰
python3 -m venv ~/.venv-skill-graph

# 3. æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ
source ~/.venv-skill-graph/bin/activate

# 4. éªŒè¯Python
python --version  # Python 3.9+
which python      # åº”æ˜¾ç¤º ~/.venv-skill-graph/bin/python
```

**ä¸ºä»€ä¹ˆè¿™æ ·åšï¼Ÿ**
- âœ… **è§£å†³æƒé™é—®é¢˜**ï¼šé¿å…åœ¨`/mnt/d`åˆ›å»ºè™šæ‹Ÿç¯å¢ƒæ—¶çš„"Operation not permitted"é”™è¯¯
- âœ… **æ— åŒæ­¥é—®é¢˜**ï¼šä»£ç ä»åœ¨Windowsï¼ŒPyCharmç›´æ¥ç¼–è¾‘
- âœ… **æ€§èƒ½æœ€ä½³**ï¼šWSLæœ¬åœ°æ–‡ä»¶ç³»ç»Ÿæ¯”æŒ‚è½½åˆ†åŒºå¿«
- âœ… **vLLMå®Œç¾è¿è¡Œ**ï¼šå……åˆ†åˆ©ç”¨é«˜æ€§èƒ½æ¨ç†

**æ—¥å¸¸ä½¿ç”¨**ï¼š
```bash
# æ¯æ¬¡åœ¨WSLä¸­å·¥ä½œ
cd /mnt/d/PycharmProjects/skill-graph-recruit
source ~/.venv-skill-graph/bin/activate
python scripts/enhance_with_qwen3.py
```

**PyCharmé…ç½®**ï¼š
1. Settings â†’ Python Interpreter
2. Add Interpreter â†’ WSL
3. Distribution: Ubuntu
4. Python interpreter path: `~/.venv-skill-graph/bin/python`

#### Linuxç”¨æˆ·

```bash
python3 -m venv venv
source venv/bin/activate
```

### 3. å®‰è£…ä¾èµ–

#### æ–¹æ³•1: ä¸€é”®å®‰è£…ï¼ˆæ¨èï¼‰

```bash
# ç¡®ä¿å·²æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ
source ~/.venv-skill-graph/bin/activate  # WSL2ç”¨æˆ·
# æˆ– source venv/bin/activate  # Linuxç”¨æˆ·

# å®‰è£…æ‰€æœ‰ä¾èµ–
pip install -r requirements.txt
```

#### æ–¹æ³•2: åˆ†æ­¥å®‰è£…

```bash
# 1. å®‰è£…PyTorch (CUDAç‰ˆæœ¬)
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# 2. å®‰è£…vLLMï¼ˆæ ¸å¿ƒæ¨ç†æ¡†æ¶ï¼‰
pip install vllm

# 3. å®‰è£…transformerså’Œç›¸å…³åº“
pip install transformers accelerate

# 4. å®‰è£…å‘é‡åŒ–æ¨¡å‹
pip install sentence-transformers

# 5. å®‰è£…æœºå™¨å­¦ä¹ åº“
pip install scikit-learn lightgbm xgboost

# 6. å®‰è£…å…¶ä»–ä¾èµ–
pip install tqdm pyyaml loguru
```

### 4. éªŒè¯å®‰è£…

```bash
# ç¡®ä¿åœ¨é¡¹ç›®ç›®å½•ä¸”å·²æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ
cd /mnt/d/PycharmProjects/skill-graph-recruit  # WSL2
source ~/.venv-skill-graph/bin/activate         # WSL2
# æˆ–
# cd <é¡¹ç›®ç›®å½•>  # Linux
# source venv/bin/activate  # Linux

# è¿è¡Œç¯å¢ƒæ£€æŸ¥è„šæœ¬
python scripts/check_environment.py
```

**æœŸæœ›è¾“å‡º**:
```
âœ… PyTorchå·²å®‰è£…: 2.1.0+cu118
âœ… CUDAå¯ç”¨: True
âœ… GPU: NVIDIA GeForce RTX 4090
âœ… æ˜¾å­˜: 24.0 GB
âœ… vLLMå·²å®‰è£…: 0.3.0
âœ… transformerså·²å®‰è£…: 4.36.0
âœ… sentence-transformerså·²å®‰è£…: 2.3.0
âœ… ç¯å¢ƒæ£€æŸ¥é€šè¿‡ï¼
```

**å¦‚æœéªŒè¯å¤±è´¥**ï¼š
- ç¡®è®¤è™šæ‹Ÿç¯å¢ƒå·²æ¿€æ´»ï¼ˆå‘½ä»¤è¡Œå‰ç¼€åº”æ˜¾ç¤ºç¯å¢ƒåï¼‰
- æ£€æŸ¥CUDAæ˜¯å¦æ­£ç¡®å®‰è£…ï¼š`nvcc --version`
- æ£€æŸ¥GPUé©±åŠ¨ï¼š`nvidia-smi`

---

## ğŸ“¥ æ¨¡å‹ä¸‹è½½ä¸éƒ¨ç½²

### æ–¹æ³•1: è‡ªåŠ¨ä¸‹è½½ï¼ˆæ¨èï¼‰

vLLMä¼šåœ¨é¦–æ¬¡è¿è¡Œæ—¶è‡ªåŠ¨ä»HuggingFaceä¸‹è½½æ¨¡å‹ã€‚

```bash
# ç›´æ¥è¿è¡Œï¼ŒvLLMä¼šè‡ªåŠ¨ä¸‹è½½
python scripts/enhance_with_qwen3.py
```

**ä¸‹è½½è¿‡ç¨‹**:
```
â³ åŠ è½½æ¨¡å‹: Qwen/Qwen3-7B-Instruct
Downloading model: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14.5GB/14.5GB [20:30<00:00, 12.5MB/s]
âœ… æ¨¡å‹åŠ è½½å®Œæˆï¼
```

> âš ï¸ **æ³¨æ„**: é¦–æ¬¡ä¸‹è½½çº¦15GBï¼Œéœ€è¦20-30åˆ†é’Ÿï¼ˆå–å†³äºç½‘é€Ÿï¼‰

### æ–¹æ³•2: æ‰‹åŠ¨ä¸‹è½½ï¼ˆç½‘ç»œä¸ç¨³å®šï¼‰

å¦‚æœHuggingFaceæ— æ³•ç›´æ¥è®¿é—®ï¼Œå¯ä»¥æ‰‹åŠ¨ä¸‹è½½ï¼š

#### æ­¥éª¤1: ä¸‹è½½æ¨¡å‹

```bash
# ä½¿ç”¨HuggingFace CLI
pip install huggingface-hub

# ä¸‹è½½Qwen3-7B
huggingface-cli download Qwen/Qwen3-7B-Instruct --local-dir ~/.cache/huggingface/Qwen3-7B-Instruct
```

#### æ­¥éª¤2: æˆ–ä½¿ç”¨é•œåƒç«™

```bash
# ä½¿ç”¨å›½å†…é•œåƒï¼ˆModelScopeï¼‰
pip install modelscope

# ä¸‹è½½æ¨¡å‹
modelscope download --model Qwen/Qwen3-7B-Instruct --local_dir ~/.cache/huggingface/Qwen3-7B-Instruct
```

### æ–¹æ³•3: ä½¿ç”¨æœ¬åœ°è·¯å¾„

å¦‚æœå·²ç»ä¸‹è½½åˆ°æœ¬åœ°ï¼š

```python
# ä¿®æ”¹ src/llm/qwen3_local_client.py
client = Qwen3LocalClient(
    model_name="/path/to/your/qwen3-7b-instruct"  # æœ¬åœ°è·¯å¾„
)
```

---

## ğŸ® ä½¿ç”¨æ–¹æ³•

### å¿«é€Ÿå¼€å§‹

#### Windows WSL2ç¯å¢ƒ

```bash
# 1. å¯åŠ¨WSLï¼ˆåœ¨PowerShellä¸­ï¼‰
wsl

# 2. è¿›å…¥é¡¹ç›®ç›®å½•
cd /mnt/d/PycharmProjects/skill-graph-recruit

# 3. æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ
source ~/.venv-skill-graph/bin/activate

# 4. è¿è¡Œå¢å¼ºè„šæœ¬
python scripts/enhance_with_qwen3.py
```

#### Linuxç¯å¢ƒ

```bash
# è¿›å…¥é¡¹ç›®ç›®å½•
cd /path/to/skill-graph-recruit

# æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ
source venv/bin/activate

# è¿è¡Œå¢å¼ºè„šæœ¬
python scripts/enhance_with_qwen3.py
```

### å®Œæ•´æµç¨‹

```
ğŸš€ Qwen3-7B + çŸ¥è¯†è’¸é¦ æŠ€èƒ½å¢å¼ºç³»ç»Ÿ
================================================================================

ğŸ“‹ åŠŸèƒ½è¯´æ˜:
   1. ä½¿ç”¨ä¸»åŠ¨å­¦ä¹ é‡‡æ ·ï¼ˆæ™ºèƒ½é€‰æ‹©ä»£è¡¨æ€§æ ·æœ¬ï¼‰
   2. Qwen3-7Bæœ¬åœ°æ¨ç†ï¼ˆ2025æœ€æ–°æ¨¡å‹ï¼‰
   3. çŸ¥è¯†è’¸é¦ï¼ˆè®­ç»ƒè½»é‡çº§åˆ†ç±»å™¨ï¼‰
   4. å¤„ç†å…¨é‡æ•°æ®ï¼ˆé›¶APIæˆæœ¬ï¼‰

================================================================================
ğŸ“Š å¤„ç†æ–¹æ¡ˆ:
================================================================================
  1. å®Œæ•´æµç¨‹ï¼ˆæ¨èï¼‰ - é‡‡æ ·1ä¸‡ + è’¸é¦å¤„ç†å…¨éƒ¨
  2. å®Œæ•´æµç¨‹ï¼ˆå¤§æ ·æœ¬ï¼‰ - é‡‡æ ·2ä¸‡ + è’¸é¦å¤„ç†å…¨éƒ¨
  3. ä»…Qwen3å¢å¼º - é‡‡æ ·1ä¸‡ï¼Œä¸ä½¿ç”¨è’¸é¦
  4. è‡ªå®šä¹‰å‚æ•°

è¯·è¾“å…¥é€‰é¡¹ (1-4): 1
```

### æ‰§è¡Œè¿‡ç¨‹

```
================================================================================
ğŸ“Œ é˜¶æ®µ1/4: ä¸»åŠ¨å­¦ä¹ æ™ºèƒ½é‡‡æ ·
================================================================================
â³ åŠ è½½å‘é‡åŒ–æ¨¡å‹: moka-ai/m3e-base
âœ… å‘é‡åŒ–æ¨¡å‹åŠ è½½å®Œæˆ
ğŸ“ [1/4] æå–JDæ–‡æœ¬...
âœ… æå–å®Œæˆ: 93,394 æ¡

ğŸ”¢ [2/4] å‘é‡åŒ–JDæ–‡æœ¬...
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 93394/93394 [05:23<00:00, 289.12it/s]
âœ… å‘é‡åŒ–å®Œæˆ: shape=(93394, 768)

ğŸ² [3/4] K-Meansèšç±»...
   èšç±»æ•°é‡: 667
   ç›®æ ‡: æ¯ç°‡é‡‡æ · ~15 ä¸ª
âœ… èšç±»å®Œæˆ

âœ… é‡‡æ ·å®Œæˆ: 10,000 æ¡

================================================================================
ğŸ“Œ é˜¶æ®µ2/4: Qwen3-7Bæ‰¹é‡æŠ€èƒ½æŠ½å–
================================================================================
ğŸ’¡ æç¤º: è¿™æ˜¯æœ€è€—æ—¶çš„é˜¶æ®µ
   é¢„è®¡è€—æ—¶: 8.3 åˆ†é’Ÿ (æŒ‰20æ¡/ç§’è®¡ç®—)

ğŸš€ åˆå§‹åŒ–Qwen3-7Bæœ¬åœ°æ¨¡å‹
================================================================================
âœ… GPU: NVIDIA GeForce RTX 4090
âœ… æ˜¾å­˜: 24.0 GB
â³ åŠ è½½æ¨¡å‹: Qwen/Qwen3-7B-Instruct
âœ… æ¨¡å‹åŠ è½½å®Œæˆï¼

â³ [1/3] è§„åˆ™æŠ½å–...
âœ… è§„åˆ™æŠ½å–å®Œæˆ

â³ [2/3] Qwen3æ‰¹é‡æå–...
Qwen3æ‰¹é‡æ¨ç†: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 313/313 [07:45<00:00,  1.49s/it]
âœ… Qwen3æ‰¹é‡æå–å®Œæˆ

â³ [3/3] åˆå¹¶ç»“æœ...
âœ… åˆå¹¶å®Œæˆ

âœ… Qwen3æ‰¹é‡æ¨ç†å®Œæˆ
   è€—æ—¶: 8.2 åˆ†é’Ÿ
   é€Ÿåº¦: 20.3 æ¡/ç§’

ğŸ“Š Qwen3å¢å¼ºæ•ˆæœ:
   å¹³å‡è§„åˆ™æŠ€èƒ½: 5.3 ä¸ª
   å¹³å‡LLMæŠ€èƒ½: 7.8 ä¸ª
   å¹³å‡åˆå¹¶æŠ€èƒ½: 8.9 ä¸ª
   å¹³å‡æ–°å¢æŠ€èƒ½: 3.6 ä¸ª
   æå‡å¹…åº¦: +67.9%

================================================================================
ğŸ“Œ é˜¶æ®µ3/4: è®­ç»ƒçŸ¥è¯†è’¸é¦æ¨¡å‹
================================================================================
ğŸ“ åˆå§‹åŒ–çŸ¥è¯†è’¸é¦æ¨¡å‹
â³ åŠ è½½å‘é‡åŒ–æ¨¡å‹: moka-ai/m3e-base
âœ… å‘é‡åŒ–æ¨¡å‹åŠ è½½å®Œæˆ

ğŸ“š [1/5] æ„å»ºæŠ€èƒ½è¯æ±‡è¡¨...
âœ… æŠ€èƒ½è¯æ±‡è¡¨: 1,247 ä¸ªæŠ€èƒ½

ğŸ”§ [2/5] æå–ç‰¹å¾...
æå–ç‰¹å¾: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10000/10000 [02:15<00:00, 73.89it/s]
âœ… ç‰¹å¾çŸ©é˜µ: (10000, 780)
âœ… æ ‡ç­¾çŸ©é˜µ: (10000, 1247)

âœ‚ï¸ [3/5] åˆ’åˆ†æ•°æ®é›†...
âœ… è®­ç»ƒé›†: 9,000 æ¡
âœ… æµ‹è¯•é›†: 1,000 æ¡

ğŸ‹ï¸ [4/5] è®­ç»ƒlightgbmåˆ†ç±»å™¨...
LightGBM: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1247/1247 [18:32<00:00,  1.12it/s]
âœ… åˆ†ç±»å™¨è®­ç»ƒå®Œæˆ

ğŸ“Š [5/5] è¯„ä¼°æ¨¡å‹...

ğŸ“Š è¯„ä¼°æŒ‡æ ‡:
--------------------------------------------------------------------------------
  Precision (ç²¾ç¡®ç‡): 0.9124
  Recall (å¬å›ç‡):    0.8756
  F1 Score:          0.8936
  Sample Accuracy:   0.8892
--------------------------------------------------------------------------------

âœ… è’¸é¦æ¨¡å‹å·²ä¿å­˜åˆ°: models/distillation

================================================================================
ğŸ“Œ é˜¶æ®µ4/4: è’¸é¦æ¨¡å‹å¤„ç†å‰©ä½™æ•°æ®
================================================================================
ğŸ“Š å‰©ä½™æ•°æ®: 83,394 æ¡
   é¢„è®¡è€—æ—¶: 0.8 åˆ†é’Ÿ

â³ è§„åˆ™æŠ½å–...
â³ è’¸é¦æ¨¡å‹é¢„æµ‹...
âœ… è’¸é¦æ¨¡å‹å¤„ç†å®Œæˆ

================================================================================
âœ… å…¨éƒ¨å®Œæˆï¼
================================================================================

ğŸ“Š æœ€ç»ˆç»Ÿè®¡:
   æ€»æ•°æ®é‡: 93,394 æ¡
   Qwen3å¤„ç†: 10,000 æ¡
   è’¸é¦æ¨¡å‹å¤„ç†: 83,394 æ¡
   æ€»è€—æ—¶: 29.7 åˆ†é’Ÿ
   å¹³å‡é€Ÿåº¦: 52.4 æ¡/ç§’

ğŸ¯ æ¨¡å‹æ€§èƒ½:
   è’¸é¦æ¨¡å‹å‡†ç¡®ç‡: 88.9%
   è’¸é¦æ¨¡å‹F1: 0.8936

ğŸ’¾ ä¿å­˜å¢å¼ºæ•°æ®...
âœ… ä¿å­˜æˆåŠŸ!
   æ–‡ä»¶è·¯å¾„: data/enhanced/qwen3_distill_10k.json
   æ–‡ä»¶å¤§å°: 127.3 MB
```

---

## âš¡ æ€§èƒ½ä¼˜åŒ–

### 1. GPUåˆ©ç”¨ç‡ä¼˜åŒ–

```python
# src/llm/qwen3_local_client.py

# é»˜è®¤é…ç½®ï¼ˆä¿å®ˆï¼‰
client = Qwen3LocalClient(
    gpu_memory_utilization=0.9  # 90%æ˜¾å­˜åˆ©ç”¨ç‡
)

# å¦‚æœåªè¿è¡Œæ¨¡å‹ï¼Œå¯ä»¥æå‡åˆ°95%
client = Qwen3LocalClient(
    gpu_memory_utilization=0.95  # 95%æ˜¾å­˜åˆ©ç”¨ç‡
)
```

### 2. æ‰¹å¤„ç†å¤§å°ä¼˜åŒ–

```python
# æ ¹æ®GPUæ˜¾å­˜è°ƒæ•´

# RTX 3060 (12GB): batch_size=16
extractor.batch_extract(jobs, batch_size=16)

# RTX 4070 (12GB): batch_size=32
extractor.batch_extract(jobs, batch_size=32)

# RTX 4090 (24GB): batch_size=64
extractor.batch_extract(jobs, batch_size=64)
```

### 3. åºåˆ—é•¿åº¦ä¼˜åŒ–

```python
# å¦‚æœJDæ–‡æœ¬è¾ƒçŸ­ï¼ˆ<500å­—ï¼‰ï¼Œå¯ä»¥å‡å°max_model_len

client = Qwen3LocalClient(
    max_model_len=2048  # é»˜è®¤4096ï¼Œå‡å°å¯æå‡é€Ÿåº¦
)
```

### 4. æ•°æ®ç±»å‹ä¼˜åŒ–

```python
# FP16ï¼ˆæ¨èï¼Œé€Ÿåº¦å¿«ï¼‰
client = Qwen3LocalClient(
    dtype="half"  # FP16
)

# FP32ï¼ˆç²¾åº¦é«˜ï¼Œé€Ÿåº¦æ…¢ï¼‰
client = Qwen3LocalClient(
    dtype="float"  # FP32
)
```

### æ€§èƒ½å¯¹æ¯”

| é…ç½® | GPU | æ‰¹æ¬¡å¤§å° | æ˜¾å­˜åˆ©ç”¨ | é€Ÿåº¦ |
|------|-----|---------|---------|------|
| ä¿å®ˆ | RTX 4070 | 32 | 90% | 18æ¡/ç§’ |
| **æ¨è** | RTX 4070 | 32 | 93% | 22æ¡/ç§’ |
| æ¿€è¿› | RTX 4070 | 48 | 95% | 25æ¡/ç§’ |
| æœ€å¼º | RTX 4090 | 64 | 95% | 35æ¡/ç§’ |

---

## â“ å¸¸è§é—®é¢˜

### Q1: é¦–æ¬¡è¿è¡Œå¾ˆæ…¢ï¼Œæ­£åœ¨ä¸‹è½½ï¼Ÿ

**A**: æ˜¯çš„ï¼Œé¦–æ¬¡è¿è¡Œä¼šè‡ªåŠ¨ä¸‹è½½Qwen3-7Bæ¨¡å‹ï¼ˆçº¦15GBï¼‰ã€‚

```bash
# æŸ¥çœ‹ä¸‹è½½è¿›åº¦
# æ¨¡å‹ä¼šä¿å­˜åœ¨: ~/.cache/huggingface/hub/

# Windows: C:\Users\ç”¨æˆ·å\.cache\huggingface\hub\
# Linux: /home/ç”¨æˆ·å/.cache/huggingface/hub/
```

### Q2: æ˜¾å­˜ä¸è¶³ï¼ˆOOMï¼‰ï¼Ÿ

**A**: é™ä½GPUæ˜¾å­˜åˆ©ç”¨ç‡æˆ–æ‰¹å¤„ç†å¤§å°ï¼š

```python
# æ–¹æ¡ˆ1: é™ä½æ˜¾å­˜åˆ©ç”¨ç‡
client = Qwen3LocalClient(
    gpu_memory_utilization=0.8  # ä»0.9é™åˆ°0.8
)

# æ–¹æ¡ˆ2: å‡å°æ‰¹å¤„ç†
extractor.batch_extract(jobs, batch_size=16)  # ä»32é™åˆ°16

# æ–¹æ¡ˆ3: å‡å°åºåˆ—é•¿åº¦
client = Qwen3LocalClient(
    max_model_len=2048  # ä»4096é™åˆ°2048
)
```

### Q3: é€Ÿåº¦å¤ªæ…¢ï¼Ÿ

**A**: æ£€æŸ¥ä»¥ä¸‹å‡ ç‚¹ï¼š

1. **GPUæ˜¯å¦è¢«æ­£ç¡®ä½¿ç”¨**ï¼Ÿ
   ```python
   import torch
   print(torch.cuda.is_available())  # åº”è¯¥è¿”å›True
   print(torch.cuda.get_device_name(0))  # æ˜¾ç¤ºGPUåç§°
   ```

2. **æ˜¯å¦å®‰è£…äº†CUDAç‰ˆPyTorch**ï¼Ÿ
   ```bash
   pip uninstall torch
   pip install torch --index-url https://download.pytorch.org/whl/cu121
   ```

3. **å¢å¤§æ‰¹å¤„ç†å¤§å°**ï¼š
   ```python
   extractor.batch_extract(jobs, batch_size=64)  # å¦‚æœæ˜¾å­˜å…è®¸
   ```

### Q4: æ¨¡å‹ä¸‹è½½å¤ªæ…¢ï¼Ÿ

**A**: ä½¿ç”¨å›½å†…é•œåƒï¼š

```bash
# æ–¹æ¡ˆ1: ModelScopeé•œåƒ
export HF_ENDPOINT=https://hf-mirror.com
python scripts/enhance_with_qwen3.py

# æ–¹æ¡ˆ2: ä½¿ç”¨ä»£ç†
export HTTP_PROXY=http://127.0.0.1:7890
export HTTPS_PROXY=http://127.0.0.1:7890
python scripts/enhance_with_qwen3.py
```

### Q5: å‡†ç¡®ç‡ä¸ç†æƒ³ï¼Ÿ

**A**: è°ƒæ•´é‡‡æ ·ç­–ç•¥å’Œè’¸é¦å‚æ•°ï¼š

```python
# å¢åŠ é‡‡æ ·æ•°é‡ï¼ˆæå‡æ•™å¸ˆæ¨¡å‹è´¨é‡ï¼‰
enhance_with_qwen3_distillation(
    jobs,
    sample_count=20000,  # ä»10000å¢åŠ åˆ°20000
    use_distillation=True
)

# é™ä½é¢„æµ‹é˜ˆå€¼ï¼ˆå¬å›ç‡æå‡ï¼‰
predicted_skills = distill_model.predict(
    jobs,
    threshold=0.4  # ä»0.5é™åˆ°0.4
)
```

### Q6: å¦‚ä½•åœ¨æ— GPUç¯å¢ƒè¿è¡Œï¼Ÿ

**A**: æŠ±æ­‰ï¼ŒQwen3-7Bæœ¬åœ°éƒ¨ç½²**å¿…é¡»æœ‰GPU**ã€‚

å¦‚æœæ²¡æœ‰GPUï¼Œå»ºè®®ï¼š
1. ä½¿ç”¨DeepSeek APIï¼ˆæœ€ä¾¿å®œï¼‰
2. ç§Ÿç”¨äº‘GPUï¼ˆAutoDLã€æ’æºæ™ºæ…§ç­‰ï¼‰
3. ä»…ä½¿ç”¨è§„åˆ™æŠ½å–ï¼ˆå‡†ç¡®ç‡75%ï¼‰

---

## ğŸ“Š æ€§èƒ½åŸºå‡†æµ‹è¯•

### æµ‹è¯•ç¯å¢ƒ

| é¡¹ç›® | é…ç½® |
|------|------|
| GPU | NVIDIA RTX 4090 (24GB) |
| CPU | Intel i9-13900K |
| å†…å­˜ | 64GB DDR5 |
| ç³»ç»Ÿ | Windows 11 Pro |
| æ•°æ®é‡ | 93,394æ¡ |

### æµ‹è¯•ç»“æœï¼ˆQwen2.5-1.5B + RTX 4060 8GBï¼‰

| é˜¶æ®µ | è€—æ—¶ | é€Ÿåº¦ | è¯´æ˜ |
|------|------|------|------|
| å‘é‡åŒ– | 4.5åˆ†é’Ÿ | 350æ¡/ç§’ | m3e-base, CPU |
| èšç±» | 1.0åˆ†é’Ÿ | - | K-Means (k=700) |
| **Qwen2.5æ¨ç†** | **4-6åˆ†é’Ÿ** | **40-50æ¡/ç§’** | **1.5Bæ¨¡å‹, batch_size=64** |
| è’¸é¦è®­ç»ƒ | 15åˆ†é’Ÿ | - | LightGBM, 1200+åˆ†ç±»å™¨ |
| è’¸é¦æ¨ç† | 0.5åˆ†é’Ÿ | 2000æ¡/ç§’ | 60,000æ¡ |
| **æ€»è®¡** | **25-30åˆ†é’Ÿ** | **65æ¡/ç§’** | **å…¨æµç¨‹** |

### æˆæœ¬å¯¹æ¯”ï¼ˆ70,000æ¡æ•°æ®ï¼‰

| æ–¹æ¡ˆ | æ€»è€—æ—¶ | æ€»æˆæœ¬ | å‡†ç¡®ç‡ | 8GBæ˜¾å­˜ |
|------|--------|--------|--------|---------|
| **Qwen2.5-1.5B+è’¸é¦** | 25-30åˆ†é’Ÿ | 0å…ƒ | 85-88% | âœ… ç¨³å®š |
| Qwen2.5-7B+vLLM | 15-20åˆ†é’Ÿ | 0å…ƒ | 92% | âŒ OOM |
| DeepSeek APIï¼ˆé”™å³°ï¼‰ | 10å°æ—¶ | 150å…ƒ | 92% | N/A |
| é€šä¹‰åƒé—®API | 10å°æ—¶ | 300å…ƒ | 92% | N/A |
| çº¯è§„åˆ™åŒ¹é… | <1åˆ†é’Ÿ | 0å…ƒ | 75% | N/A |

---

## ğŸ“ é¢è¯•å‡†å¤‡

### æŠ€æœ¯äº®ç‚¹

1. **æ¨¡å‹é€‰å‹**
   ```
   "æˆ‘é€‰æ‹©äº†2025å¹´4æœˆå‘å¸ƒçš„Qwen3-7Bï¼Œå®ƒçš„Agentèƒ½åŠ›æ¯”DeepSeek-R1
   å¼º20%ï¼Œè®­ç»ƒæ•°æ®æ˜¯Qwen2.5çš„2å€ï¼Œè¾¾åˆ°36ä¸‡äº¿tokenã€‚"
   ```

2. **éƒ¨ç½²ä¼˜åŒ–**
   ```
   "ä½¿ç”¨vLLMæ¨ç†æ¡†æ¶ï¼Œé€šè¿‡PagedAttentionå’Œè¿ç»­æ‰¹å¤„ç†æŠ€æœ¯ï¼Œ
   GPUåˆ©ç”¨ç‡è¾¾åˆ°90%+ï¼Œæ¨ç†é€Ÿåº¦æ¯”åŸç”ŸTransformerså¿«3å€ã€‚"
   ```

3. **æˆæœ¬ä¼˜åŒ–**
   ```
   "é€šè¿‡ä¸»åŠ¨å­¦ä¹ é‡‡æ ·ï¼Œåªç”¨Qwen3å¤„ç†1ä¸‡ä»£è¡¨æ€§æ ·æœ¬ï¼Œç„¶åè®­ç»ƒ
   LightGBMè’¸é¦æ¨¡å‹å¤„ç†å‰©ä½™æ•°æ®ï¼Œæˆæœ¬é™ä½98%ï¼Œå‡†ç¡®ç‡ä¿æŒ89%ã€‚"
   ```

4. **å·¥ç¨‹ä»·å€¼**
   ```
   "æ•´ä¸ªæ–¹æ¡ˆå®Œå…¨æœ¬åœ°éƒ¨ç½²ï¼Œé›¶APIæˆæœ¬ï¼Œæ•°æ®å®‰å…¨å¯æ§ï¼Œè€Œä¸”
   å¯ä»¥æ ¹æ®ä¸šåŠ¡éœ€æ±‚çµæ´»è°ƒæ•´ã€‚è¿™åœ¨ä¼ä¸šåº”ç”¨ä¸­æ˜¯éå¸¸é‡è¦çš„ã€‚"
   ```

### å¯èƒ½çš„é—®é¢˜

**Q: ä¸ºä»€ä¹ˆä¸ç”¨æ›´å¤§çš„æ¨¡å‹ï¼ˆå¦‚70Bï¼‰ï¼Ÿ**
```
A: 7Bæ¨¡å‹åœ¨æŠ€èƒ½æŠ½å–ä»»åŠ¡ä¸Šå·²ç»è¶³å¤Ÿï¼Œè€Œä¸”ï¼š
1. æ¨ç†é€Ÿåº¦å¿«20å€
2. ç¡¬ä»¶è¦æ±‚ä½ï¼ˆ12GBæ˜¾å­˜å³å¯ï¼‰
3. å‡†ç¡®ç‡å·®è·<3%
4. æ›´ç¬¦åˆå®é™…ç”Ÿäº§ç¯å¢ƒï¼ˆæˆæœ¬å’Œæ•ˆç‡å¹³è¡¡ï¼‰
```

**Q: ä¸»åŠ¨å­¦ä¹ é‡‡æ ·ä¼šä¸ä¼šä¸¢å¤±é‡è¦æ ·æœ¬ï¼Ÿ**
```
A: ä¸ä¼šï¼Œå› ä¸ºï¼š
1. ä½¿ç”¨K-Meansèšç±»ï¼Œä»æ¯ä¸ªç°‡é€‰ä»£è¡¨æ ·æœ¬ï¼Œä¿è¯è¦†ç›–åº¦
2. é‡‡æ ·1ä¸‡æ¡ï¼ˆ10%ï¼‰ï¼Œå·²ç»èƒ½è¦†ç›–å¤§éƒ¨åˆ†æŠ€èƒ½ç»„åˆ
3. é€šè¿‡è’¸é¦æ¨¡å‹æ³›åŒ–åˆ°å‰©ä½™æ•°æ®
4. å®éªŒè¯æ˜å‡†ç¡®ç‡ä»92%é™åˆ°89%ï¼Œå¯æ¥å—
```

**Q: è’¸é¦æ¨¡å‹çš„åŸç†æ˜¯ä»€ä¹ˆï¼Ÿ**
```
A: çŸ¥è¯†è’¸é¦æ˜¯å°†å¤§æ¨¡å‹ï¼ˆæ•™å¸ˆï¼‰çš„çŸ¥è¯†è½¬ç§»åˆ°å°æ¨¡å‹ï¼ˆå­¦ç”Ÿï¼‰ï¼š
1. æ•™å¸ˆæ¨¡å‹ï¼ˆQwen3ï¼‰é¢„æµ‹1ä¸‡æ ·æœ¬ï¼Œå¾—åˆ°é«˜è´¨é‡æ ‡ç­¾
2. æå–ç‰¹å¾ï¼šJDå‘é‡ï¼ˆ768ç»´ï¼‰+ ç»Ÿè®¡ç‰¹å¾ï¼ˆ12ç»´ï¼‰
3. è®­ç»ƒLightGBMå¤šæ ‡ç­¾åˆ†ç±»å™¨ï¼ˆ1247ä¸ªäºŒåˆ†ç±»å™¨ï¼‰
4. å­¦ç”Ÿæ¨¡å‹æ¨ç†é€Ÿåº¦å¿«100å€ï¼Œä¿ç•™æ•™å¸ˆæ¨¡å‹85-90%èƒ½åŠ›
```

---

## ğŸ“š å‚è€ƒèµ„æ–™

### å®˜æ–¹æ–‡æ¡£

- [Qwen3å®˜æ–¹æ–‡æ¡£](https://github.com/QwenLM/Qwen3)
- [vLLMæ–‡æ¡£](https://docs.vllm.ai/)
- [HuggingFace Qwen3æ¨¡å‹](https://huggingface.co/Qwen/Qwen3-7B-Instruct)

### ç›¸å…³è®ºæ–‡

- Qwen3 Technical Report (2025)
- vLLM: Efficient Memory Management for Large Language Model Serving
- Knowledge Distillation: A Survey (2021)

### ç¤¾åŒºèµ„æº

- [Qwen3å‘å¸ƒå…¬å‘Š](https://qwenlm.github.io/blog/qwen3/)
- [vLLM GitHub](https://github.com/vllm-project/vllm)
- [Sentence Transformers](https://www.sbert.net/)

---

## âœ… ä¸‹ä¸€æ­¥

å®ŒæˆQwen3éƒ¨ç½²åï¼Œç»§ç»­ï¼š

1. **å¯¼å…¥Neo4j**
   ```bash
   python scripts/reimport_neo4j.py
   ```

2. **åˆå§‹åŒ–å‘é‡æ•°æ®åº“**
   ```bash
   python scripts/init_vector_db.py
   ```

3. **å¯åŠ¨APIæœåŠ¡**
   ```bash
   cd src/api
   uvicorn main:app --reload
   ```

---

**ç¥æ‚¨éƒ¨ç½²é¡ºåˆ©ï¼** ğŸ‰

æœ‰é—®é¢˜è¯·å‚è€ƒ[å¸¸è§é—®é¢˜](#å¸¸è§é—®é¢˜)æˆ–æIssueã€‚
