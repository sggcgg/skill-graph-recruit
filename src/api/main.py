"""
FastAPIä¸»åº”ç”¨
æä¾›æ™ºèƒ½æ‹›è˜åˆ†æçš„REST APIæœåŠ¡
"""
import asyncio
import logging
import uuid
import time
import yaml
from fastapi import FastAPI, HTTPException, Body, Query
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse
from pydantic import BaseModel, Field
from typing import List, Optional, Dict, Any, Tuple
from pathlib import Path
import sys

# ===== ç®€æ˜“ TTL å†…å­˜ç¼“å­˜ =====
_api_cache: Dict[str, Tuple[Any, float]] = {}

def cache_get(key: str) -> Optional[Any]:
    """ä»ç¼“å­˜è¯»å–ï¼Œè¿‡æœŸè¿”å› None"""
    if key in _api_cache:
        value, expire_at = _api_cache[key]
        if time.time() < expire_at:
            return value
        del _api_cache[key]
    return None

def cache_set(key: str, value: Any, ttl: int = 300) -> None:
    """å†™å…¥ç¼“å­˜ï¼Œttl å•ä½ç§’"""
    _api_cache[key] = (value, time.time() + ttl)

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°path
project_root = Path(__file__).parent.parent.parent
if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))

from src.rag.rag_service import RAGService
from src.agent.job_agent import JobRecommendAgent
from src.nlp.hybrid_skill_extractor import HybridSkillExtractor
from src.auth.routes import include_auth_routes
from src.database.database import init_db

logger = logging.getLogger(__name__)

# è·å–é¡¹ç›®æ ¹ç›®å½•å¹¶åŠ è½½é…ç½®
project_root_for_config = Path(__file__).parent.parent.parent
config_path_abs = project_root_for_config / 'config.yaml'

with open(config_path_abs, 'r', encoding='utf-8') as f:
    config = yaml.safe_load(f)

api_config = config.get('api', {})

# åˆ›å»ºFastAPIåº”ç”¨
app = FastAPI(
    title=api_config.get('title', 'æ™ºèƒ½æ‹›è˜åˆ†æAPI'),
    description=api_config.get('description', 'åŸºäºLLM+RAGçš„æ™ºèƒ½æ‹›è˜ä¿¡æ¯èšåˆåˆ†æç³»ç»Ÿ'),
    version=api_config.get('version', '2.0.0'),
    docs_url="/docs",
    redoc_url="/redoc"
)

# æ·»åŠ CORSä¸­é—´ä»¶
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# å…¨å±€æœåŠ¡å®ä¾‹ï¼ˆå¯åŠ¨æ—¶åˆå§‹åŒ–ï¼‰
rag_service = None
agent = None
skill_extractor = None
neo4j_manager = None


# ===== æ•°æ®æ¨¡å‹ =====

class SkillExtractRequest(BaseModel):
    """æŠ€èƒ½æŠ½å–è¯·æ±‚"""
    title: str = Field(..., description="å²—ä½æ ‡é¢˜")
    jd_text: Optional[str] = Field(None, description="èŒä½æè¿°æ–‡æœ¬")
    explicit_skills: List[str] = Field(default=[], description="æ˜¾å¼æ ‡æ³¨çš„æŠ€èƒ½")
    use_llm: bool = Field(default=True, description="æ˜¯å¦ä½¿ç”¨LLMå¢å¼º")


class SearchRequest(BaseModel):
    """æœç´¢è¯·æ±‚"""
    query: str = Field(..., description="æŸ¥è¯¢æ–‡æœ¬")
    top_k: Optional[int] = Field(default=None, ge=1, description="è¿”å›æ•°é‡ï¼ŒNone=ä¸é™")
    city: Optional[str] = Field(None, description="åŸå¸‚è¿‡æ»¤")


class SkillGapRequest(BaseModel):
    """æŠ€èƒ½å·®è·åˆ†æè¯·æ±‚"""
    user_skills: List[str] = Field(..., description="ç”¨æˆ·å½“å‰æŠ€èƒ½")
    target_position: str = Field(..., description="ç›®æ ‡å²—ä½")
    city: Optional[str] = Field(None, description="åŸå¸‚")


class RecommendRequest(BaseModel):
    """å²—ä½æ¨èè¯·æ±‚"""
    user_skills: List[str] = Field(..., description="ç”¨æˆ·æŠ€èƒ½")
    top_k: Optional[int] = Field(default=100, ge=1, le=500, description="æ¨èæ•°é‡ï¼Œæœ€å¤š500")
    city: Optional[str] = Field(None, description="åŸå¸‚è¿‡æ»¤")


class AgentChatRequest(BaseModel):
    """Agentå¯¹è¯è¯·æ±‚"""
    message: str = Field(..., description="ç”¨æˆ·æ¶ˆæ¯")
    session_id: Optional[str] = Field(None, description="ä¼šè¯ID")
    mode: str = Field("auto", description="æ£€ç´¢æ¨¡å¼ï¼šauto/graph/rag/llm")


class GraphSearchRequest(BaseModel):
    """å›¾è°±è¯­ä¹‰æœç´¢è¯·æ±‚"""
    query: str = Field(..., description="æŸ¥è¯¢è¯ï¼ˆæ”¯æŒè‡ªç„¶è¯­è¨€ï¼‰")
    top_k: Optional[int] = Field(default=None, ge=1, description="è¿”å›ç»“æœæ•°é‡ï¼ŒNone=å…¨é‡è¿”å›")
    city: Optional[str] = Field(None, description="åŸå¸‚è¿‡æ»¤")
    include_vector: bool = Field(default=False, description="æ˜¯å¦è¿½åŠ å‘é‡è¯­ä¹‰è¡¥å……ï¼ˆè¾ƒæ…¢ï¼‰")


class GraphRecommendRequest(BaseModel):
    """å›¾è°±å²—ä½æ¨èè¯·æ±‚"""
    user_skills: List[str] = Field(..., description="ç”¨æˆ·æŠ€èƒ½åˆ—è¡¨")
    top_k: Optional[int] = Field(default=100, ge=1, le=500, description="æ¨èæ•°é‡ï¼Œæœ€å¤š500")
    city: Optional[str] = Field(None, description="åŸå¸‚è¿‡æ»¤")


class GraphGapAnalysisRequest(BaseModel):
    """å›¾è°±æŠ€èƒ½å·®è·åˆ†æè¯·æ±‚"""
    user_skills: List[str] = Field(..., description="ç”¨æˆ·å½“å‰æŠ€èƒ½")
    target_position: str = Field(..., description="ç›®æ ‡å²—ä½åç§°")
    city: Optional[str] = Field(None, description="åŸå¸‚è¿‡æ»¤")


# ===== äº‹ä»¶å¤„ç† =====

@app.on_event("startup")
async def startup_event():
    """å¯åŠ¨æ—¶åˆå§‹åŒ–æœåŠ¡"""
    global rag_service, agent, skill_extractor, neo4j_manager
    
    logger.info("="*80)
    logger.info("ğŸš€ å¯åŠ¨APIæœåŠ¡...")
    logger.info("="*80)
    
    try:
        # åˆå§‹åŒ–æ•°æ®åº“
        logger.info("åˆå§‹åŒ–æ•°æ®åº“...")
        init_db()
        logger.info("âœ… æ•°æ®åº“åˆå§‹åŒ–å®Œæˆ")
        
        # åˆå§‹åŒ–RAGæœåŠ¡
        logger.info("åˆå§‹åŒ–RAGæœåŠ¡...")
        rag_service = RAGService()
        logger.info("âœ… RAGæœåŠ¡åˆå§‹åŒ–å®Œæˆ")
        
        # åˆå§‹åŒ–Agentï¼ˆä¼ å…¥å·²æœ‰ rag_serviceï¼Œé¿å…é‡å¤åŠ è½½ VectorDB å’Œ m3e-baseï¼‰
        try:
            logger.info("åˆå§‹åŒ–Agent...")
            agent = JobRecommendAgent(rag_service=rag_service)
            logger.info("âœ… Agentåˆå§‹åŒ–å®Œæˆ")
        except Exception as e:
            logger.warning(f"Agentåˆå§‹åŒ–å¤±è´¥: {e}")
            logger.warning("AgentåŠŸèƒ½å°†ä¸å¯ç”¨")
            agent = None
        
        # åˆå§‹åŒ–æŠ€èƒ½æŠ½å–å™¨
        logger.info("åˆå§‹åŒ–æŠ€èƒ½æŠ½å–å™¨...")
        skill_extractor = HybridSkillExtractor()
        logger.info("âœ… æŠ€èƒ½æŠ½å–å™¨åˆå§‹åŒ–å®Œæˆ")

        # åˆå§‹åŒ–Neo4jï¼ˆç”¨äºå›¾è°±æ¥å£ï¼‰
        try:
            logger.info("åˆå§‹åŒ–Neo4jè¿æ¥...")
            from src.graph_builder.neo4j_manager import Neo4jManager
            neo4j_cfg = config.get('neo4j', {})
            neo4j_manager = Neo4jManager(
                uri=neo4j_cfg['uri'],
                user=neo4j_cfg['user'],
                password=neo4j_cfg['password']
            )
            logger.info("âœ… Neo4jè¿æ¥åˆå§‹åŒ–å®Œæˆ")
        except Exception as e:
            logger.warning(f"Neo4jåˆå§‹åŒ–å¤±è´¥: {e}ï¼Œå›¾è°±æ¥å£å°†é™çº§ä¸ºå‘é‡æœç´¢")
            neo4j_manager = None
        
        logger.info("="*80)
        logger.info("âœ… APIæœåŠ¡å¯åŠ¨æˆåŠŸï¼")
        logger.info(f"ğŸ“– APIæ–‡æ¡£: http://localhost:{api_config.get('port', 8000)}/docs")
        logger.info("="*80)

        # åå°ï¼šç¡®ä¿ Neo4j ç´¢å¼•å­˜åœ¨ + é¢„çƒ­ç¼“å­˜ + å¯åŠ¨å®šæ—¶åˆ·æ–°ï¼ˆå‡ä¸é˜»å¡å¯åŠ¨ï¼‰
        asyncio.create_task(_ensure_neo4j_indexes())
        asyncio.create_task(_warmup_cache())
        asyncio.create_task(_cache_refresh_loop())

    except Exception as e:
        logger.error(f"âŒ æœåŠ¡åˆå§‹åŒ–å¤±è´¥: {e}")
        raise


async def _neo4j_query(cypher: str, params: dict = None):
    """æŠŠåŒæ­¥ Neo4j æŸ¥è¯¢æ”¾åˆ°çº¿ç¨‹æ± æ‰§è¡Œï¼Œé¿å…é˜»å¡ asyncio äº‹ä»¶å¾ªç¯"""
    if neo4j_manager is None:
        raise RuntimeError("Neo4j æœåŠ¡ä¸å¯ç”¨")
    return await asyncio.to_thread(neo4j_manager.execute_query, cypher, params or {})


async def _ensure_neo4j_indexes():
    """å¯åŠ¨æ—¶å¼‚æ­¥ç¡®ä¿å…³é”® Neo4j ç´¢å¼•å­˜åœ¨ï¼Œè®©æœç´¢æŸ¥è¯¢èƒ½èµ°ç´¢å¼•è€Œéå…¨è¡¨æ‰«æ"""
    if not neo4j_manager:
        return
    await asyncio.sleep(5)  # ç­‰åˆå§‹åŒ–ç¨³å®š
    indexes = [
        # Skill.name ç‚¹æŸ¥/IN æŸ¥è¯¢ç´¢å¼•ï¼ˆæŠ€èƒ½æœç´¢æ ¸å¿ƒè·¯å¾„ï¼‰
        ("CREATE INDEX skill_name_idx IF NOT EXISTS FOR (s:Skill) ON (s.name)", "Skill.name"),
        # Skill.demand_count èŒƒå›´æŸ¥è¯¢ç´¢å¼•ï¼ˆtrend/graph è¿‡æ»¤ï¼‰
        ("CREATE INDEX skill_demand_idx IF NOT EXISTS FOR (s:Skill) ON (s.demand_count)", "Skill.demand_count"),
        # Job.city åŸå¸‚ç­›é€‰ç´¢å¼•
        ("CREATE INDEX job_city_idx IF NOT EXISTS FOR (j:Job) ON (j.city)", "Job.city"),
        # Job å…¨æ–‡ç´¢å¼•ï¼šè®© j.title CONTAINS 'xxx' èµ°å…¨æ–‡æœç´¢ï¼Œè€Œéå…¨è¡¨æ‰«æ
        # æ³¨æ„ï¼šå…¨æ–‡ç´¢å¼•è¯­æ³•åœ¨ Neo4j 4.x / 5.x ä¸åŒï¼Œç”¨ try-except å…¼å®¹
    ]
    for cypher, label in indexes:
        try:
            await asyncio.to_thread(neo4j_manager.execute_query, cypher, {})
            logger.info(f"  âœ… Neo4j ç´¢å¼•ç¡®è®¤: {label}")
        except Exception as e:
            logger.debug(f"  ç´¢å¼• {label} è·³è¿‡ï¼ˆå¯èƒ½å·²å­˜åœ¨æˆ–ä¸æ”¯æŒï¼‰: {e}")

    # å…¨æ–‡ç´¢å¼•ï¼ˆJob.titleï¼‰ï¼Œè¯­æ³•å…¼å®¹ Neo4j 4.x å’Œ 5.x
    fulltext_cyphs = [
        # Neo4j 5.x è¯­æ³•
        "CREATE FULLTEXT INDEX job_title_fts IF NOT EXISTS FOR (j:Job) ON EACH [j.title]",
        # Neo4j 4.x è¯­æ³•ï¼ˆæ—  IF NOT EXISTSï¼‰
        "CALL db.index.fulltext.createNodeIndex('job_title_fts', ['Job'], ['title'])",
    ]
    for fc in fulltext_cyphs:
        try:
            await asyncio.to_thread(neo4j_manager.execute_query, fc, {})
            logger.info("  âœ… Neo4j å…¨æ–‡ç´¢å¼• job_title_fts ç¡®è®¤")
            break
        except Exception:
            pass  # å¿½ç•¥ï¼Œæ¢ä¸‹ä¸€ç§è¯­æ³•

    logger.info("âœ… Neo4j ç´¢å¼•æ£€æŸ¥å®Œæ¯•")


async def _warmup_cache():
    """
    ä¸¤é˜¶æ®µé¢„çƒ­ï¼š
    - å¿«é˜¶ï¼ˆ~2sï¼‰ï¼šåªè·‘è½»é‡æŸ¥è¯¢ï¼Œç¡®ä¿ stats/trend/graph çš„æ ¸å¿ƒæ•°æ®åœ¨æœåŠ¡å¯åŠ¨åç§’çº§å¯ç”¨
    - æ…¢é˜¶ï¼ˆåå°ï¼‰ï¼šco-occurrenceï¼ˆæŠ€èƒ½ç»„åˆï¼‰ç­‰é‡å‹æŸ¥è¯¢å¼‚æ­¥è¡¥å…¨ï¼Œä¸é˜»å¡å¿«é˜¶
    """
    await asyncio.sleep(2)  # ç­‰å¾…æœåŠ¡å®Œå…¨å°±ç»ª
    logger.info("ğŸ”¥ [å¿«é˜¶] å¼€å§‹æ ¸å¿ƒç¼“å­˜é¢„çƒ­...")

    # â”€â”€ statsï¼ˆå¿«ï¼Œ<500msï¼‰â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    try:
        if rag_service or neo4j_manager:
            stats: dict = {}
            if rag_service:
                stats['rag'] = await asyncio.to_thread(rag_service.vector_db.get_stats)
            if neo4j_manager:
                try:
                    stats['neo4j'] = await asyncio.to_thread(neo4j_manager.get_database_stats)
                except Exception:
                    stats['neo4j'] = None
            cache_set("stats", {"success": True, "data": stats}, ttl=300)
            logger.info("  âœ… /api/stats é¢„çƒ­å®Œæˆ")
    except Exception as e:
        logger.warning(f"  âš ï¸ stats é¢„çƒ­å¤±è´¥: {e}")

    if not neo4j_manager:
        logger.info("ğŸ”¥ Neo4j ä¸å¯ç”¨ï¼Œè·³è¿‡å›¾è°±é¢„çƒ­")
        return

    # â”€â”€ trend å¿«é˜¶ï¼šhot_skills + category + city_distributionï¼ˆå‡ä¸ºè½»é‡æŸ¥è¯¢ï¼‰â”€â”€
    try:
        hot_rows, cat_rows, city_rows_fast = await asyncio.gather(
            _neo4j_query("""
                MATCH (s:Skill) WHERE s.demand_count > 0
                RETURN s.name AS skill, s.category AS category,
                       s.demand_count AS demand_count, s.hot_score AS hot_score
                ORDER BY s.demand_count DESC LIMIT 100
            """),
            _neo4j_query("""
                MATCH (s:Skill) WHERE s.demand_count > 0 AND s.category IS NOT NULL
                RETURN s.category AS category, count(s) AS skill_count,
                       sum(s.demand_count) AS total_demand
                ORDER BY total_demand DESC
            """),
            _neo4j_query("""
                MATCH (j:Job)
                WHERE j.city IS NOT NULL AND j.city <> ''
                WITH j.city AS city, count(j) AS job_count
                ORDER BY job_count DESC LIMIT 15
                RETURN city, job_count
            """),
            return_exceptions=True
        )
        # å…ˆç”¨ç©ºåˆ—è¡¨å ä½ combo/salaryï¼Œæ…¢é˜¶å®Œæˆåä¼šè¦†ç›–
        cache_set("trend", {
            "success": True,
            "data": {
                "hot_skills":            [dict(r) for r in (hot_rows if isinstance(hot_rows, list) else [])],
                "category_distribution": [dict(r) for r in (cat_rows if isinstance(cat_rows, list) else [])],
                "skill_combos":          [],
                "high_salary_skills":    [],
                "city_distribution":     [{"city": r["city"], "job_count": r["job_count"]} for r in (city_rows_fast if isinstance(city_rows_fast, list) else [])],
            }
        }, ttl=600)
        logger.info("  âœ… /api/trend å¿«é˜¶é¢„çƒ­å®Œæˆï¼ˆhot_skills + category + city_distributionï¼‰")
    except Exception as e:
        logger.warning(f"  âš ï¸ trend å¿«é˜¶é¢„çƒ­å¤±è´¥: {e}")

    # â”€â”€ graphï¼ˆé»˜è®¤å‚æ•°ï¼š100èŠ‚ç‚¹ 200è¾¹ï¼‰â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    try:
        # graph å¿«é˜¶ï¼šåªé¢„çƒ­èŠ‚ç‚¹ï¼ˆè½»é‡ï¼‰ï¼Œä¸è·‘ co-occurrence è¾¹æŸ¥è¯¢
        node_rows = await _neo4j_query("""
            MATCH (s:Skill) WHERE coalesce(s.demand_count,0) >= 5
            RETURN s.name AS skill, s.category AS category,
                   coalesce(s.demand_count,0) AS demand_count,
                   coalesce(s.hot_score,0)    AS hot_score,
                   coalesce(s.avg_salary,0)   AS avg_salary
            ORDER BY demand_count DESC LIMIT 100
        """)
        node_list = [dict(r) for r in node_rows]
        # å…ˆç”¨ç©ºè¾¹åˆ—è¡¨å ä½ï¼Œæ…¢é˜¶å®Œæˆåè¦†ç›–
        cache_set("graph:100:5:200", {
            "success": True,
            "data": {"nodes": node_list, "edges": [], "node_count": len(node_list), "edge_count": 0}
        }, ttl=600)
        logger.info("  âœ… /api/graph å¿«é˜¶é¢„çƒ­å®Œæˆï¼ˆèŠ‚ç‚¹å·²ç¼“å­˜ï¼Œè¾¹å°†åœ¨æ…¢é˜¶è¡¥å…¨ï¼‰")
    except Exception as e:
        logger.warning(f"  âš ï¸ graph å¿«é˜¶é¢„çƒ­å¤±è´¥: {e}")

    # â”€â”€ graph/categoriesï¼ˆè½»é‡ï¼Œèµ° category å±æ€§ï¼‰â”€â”€â”€â”€â”€â”€
    try:
        cat_rows = await _neo4j_query(
            "MATCH (s:Skill) WHERE s.category IS NOT NULL "
            "RETURN DISTINCT s.category AS category, count(s) AS cnt ORDER BY cnt DESC"
        )
        cache_set("graph_categories", {"success": True, "data": [dict(r) for r in cat_rows]}, ttl=3600)
        logger.info("  âœ… /api/graph/categories é¢„çƒ­å®Œæˆ")
    except Exception as e:
        logger.warning(f"  âš ï¸ graph/categories é¢„çƒ­å¤±è´¥: {e}")

    logger.info("ğŸ”¥ [å¿«é˜¶] æ ¸å¿ƒç¼“å­˜é¢„çƒ­å®Œæ¯•ï¼å¯åŠ¨æ…¢é˜¶åå°è¡¥å…¨...")
    # æ…¢é˜¶ï¼šco-occurrence ç­‰é‡å‹æŸ¥è¯¢äº¤ç»™åå°ï¼Œä¸é˜»å¡æœåŠ¡å¯åŠ¨
    asyncio.create_task(_warmup_slow_phase())


async def _warmup_slow_phase():
    """æ…¢é˜¶é¢„çƒ­ï¼šco-occurrence / é«˜è–ªæŠ€èƒ½ / åŸå¸‚åˆ†å¸ƒç­‰é‡å‹æŸ¥è¯¢ï¼Œåœ¨å¿«é˜¶å®Œæˆåå¼‚æ­¥è¡¥å…¨ç¼“å­˜"""
    logger.info("ğŸ¢ [æ…¢é˜¶] å¼€å§‹è¡¥å…¨é‡å‹ç¼“å­˜ï¼ˆco-occurrence / é«˜è–ªæŠ€èƒ½ / åŸå¸‚åˆ†å¸ƒï¼‰...")
    if not neo4j_manager:
        return
    try:
        combo_rows, salary_rows, city_rows = await asyncio.gather(
            _neo4j_query("""
                MATCH (j:Job)-[:REQUIRES]->(s1:Skill),(j)-[:REQUIRES]->(s2:Skill)
                WHERE s1.name < s2.name AND s1.demand_count > 100 AND s2.demand_count > 100
                WITH s1.name AS skill1, s2.name AS skill2, count(j) AS co_count
                ORDER BY co_count DESC LIMIT 10
                RETURN skill1, skill2, co_count
            """),
            _neo4j_query("""
                MATCH (j:Job)-[:REQUIRES]->(s:Skill)
                WHERE j.salary_min > 0 AND j.salary_min < 200
                WITH s.name AS skill, avg(j.salary_min) AS avg_sal, count(j) AS job_count
                WHERE job_count >= 3
                RETURN skill, avg_sal, job_count ORDER BY avg_sal DESC LIMIT 100
            """),
            _neo4j_query("""
                MATCH (j:Job)
                WHERE j.city IS NOT NULL AND j.city <> ''
                WITH j.city AS city, count(j) AS job_count
                ORDER BY job_count DESC LIMIT 15
                RETURN city, job_count
            """),
            return_exceptions=True
        )
        # è¯»å–å¿«é˜¶å·²æœ‰çš„ trend ç¼“å­˜ï¼Œè¡¥å…… combo / salary / city
        existing = cache_get("trend") or {"success": True, "data": {}}
        existing["data"]["skill_combos"] = [dict(r) for r in (combo_rows if isinstance(combo_rows, list) else [])]
        existing["data"]["high_salary_skills"] = [
            {"skill": r["skill"], "avg_salary_k": round(r["avg_sal"] or 0, 1), "job_count": r["job_count"]}
            for r in (salary_rows if isinstance(salary_rows, list) else [])
        ]
        # åŸå¸‚æ•°æ®åœ¨å¿«é˜¶å·²å†™å…¥ï¼Œæ…¢é˜¶ç”¨æ–°æŸ¥è¯¢ç»“æœè¦†ç›–ï¼ˆæ•°æ®ç›¸åŒï¼Œä¿æŒæ–°é²œåº¦ï¼‰
        existing["data"]["city_distribution"] = [
            {"city": r["city"], "job_count": r["job_count"]}
            for r in (city_rows if isinstance(city_rows, list) else [])
        ] or existing["data"].get("city_distribution", [])
        cache_set("trend", existing, ttl=600)
        logger.info("  âœ… /api/trend æ…¢é˜¶è¡¥å…¨å®Œæˆï¼ˆskill_combos + high_salary_skills + city_distributionï¼‰")
    except Exception as e:
        logger.warning(f"  âš ï¸ trend æ…¢é˜¶è¡¥å…¨å¤±è´¥: {e}")

    try:
        # graph è¾¹æŸ¥è¯¢ï¼ˆco-occurrenceï¼Œæœ€é‡çš„æŸ¥è¯¢ï¼‰
        existing_graph = cache_get("graph:100:5:200") or {"success": True, "data": {"nodes": [], "edges": []}}
        skill_names = [n["skill"] for n in existing_graph["data"].get("nodes", [])]
        if skill_names:
            edge_rows = await _neo4j_query("""
                MATCH (j:Job)-[:REQUIRES]->(s1:Skill),(j)-[:REQUIRES]->(s2:Skill)
                WHERE s1.name < s2.name AND s1.name IN $names AND s2.name IN $names
                WITH s1.name AS skill1, s2.name AS skill2, count(j) AS co_count
                WHERE co_count >= 1
                RETURN skill1, skill2, co_count ORDER BY co_count DESC LIMIT 200
            """, {"names": skill_names})
            existing_graph["data"]["edges"] = [dict(r) for r in edge_rows]
            existing_graph["data"]["edge_count"] = len(edge_rows)
            cache_set("graph:100:5:200", existing_graph, ttl=600)
            logger.info(f"  âœ… /api/graph æ…¢é˜¶è¡¥å…¨å®Œæˆï¼ˆ{len(edge_rows)} æ¡è¾¹ï¼‰")
    except Exception as e:
        logger.warning(f"  âš ï¸ graph æ…¢é˜¶è¡¥å…¨å¤±è´¥: {e}")

    logger.info("ğŸ¢ [æ…¢é˜¶] é‡å‹ç¼“å­˜è¡¥å…¨å®Œæ¯•")


async def _cache_refresh_loop():
    """åå°å®šæ—¶åˆ·æ–°ä»»åŠ¡ï¼šæ¯ 4.5 åˆ†é’Ÿåˆ·æ–°ä¸€æ¬¡ï¼Œè®©ç¼“å­˜å§‹ç»ˆçƒ­ç€ï¼ˆstats TTL=5minï¼Œtrend/graph TTL=10minï¼‰"""
    await asyncio.sleep(270)  # é¦–æ¬¡åˆ·æ–°ç­‰ 4.5 minï¼ˆé¢„çƒ­å·²å®Œæˆï¼‰
    while True:
        logger.info("â™»ï¸  åå°ç¼“å­˜åˆ·æ–°å¼€å§‹...")
        try:
            # â”€â”€ stats â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            if rag_service or neo4j_manager:
                s: dict = {}
                if rag_service:
                    s['rag'] = await asyncio.to_thread(rag_service.vector_db.get_stats)
                if neo4j_manager:
                    try:
                        s['neo4j'] = await asyncio.to_thread(neo4j_manager.get_database_stats)
                    except Exception:
                        s['neo4j'] = None
                cache_set("stats", {"success": True, "data": s}, ttl=300)
        except Exception as e:
            logger.warning(f"  âš ï¸ stats åˆ·æ–°å¤±è´¥: {e}")

        if neo4j_manager:
            # â”€â”€ trendï¼ˆå¹¶å‘ 4 å­æŸ¥è¯¢ï¼‰â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            try:
                hot_r, cat_r, combo_r, sal_r = await asyncio.gather(
                    _neo4j_query("MATCH (s:Skill) WHERE s.demand_count > 0 RETURN s.name AS skill, s.category AS category, s.demand_count AS demand_count, s.hot_score AS hot_score ORDER BY s.demand_count DESC LIMIT 100"),
                    _neo4j_query("MATCH (s:Skill) WHERE s.demand_count > 0 AND s.category IS NOT NULL RETURN s.category AS category, count(s) AS skill_count, sum(s.demand_count) AS total_demand ORDER BY total_demand DESC"),
                    _neo4j_query("MATCH (j:Job)-[:REQUIRES]->(s1:Skill),(j)-[:REQUIRES]->(s2:Skill) WHERE s1.name < s2.name AND s1.demand_count > 100 AND s2.demand_count > 100 WITH s1.name AS skill1, s2.name AS skill2, count(j) AS co_count ORDER BY co_count DESC LIMIT 10 RETURN skill1, skill2, co_count"),
                    _neo4j_query("MATCH (j:Job)-[:REQUIRES]->(s:Skill) WHERE j.salary_min > 0 AND j.salary_min < 200 WITH s.name AS skill, avg(j.salary_min) AS avg_sal, count(j) AS job_count WHERE job_count >= 3 RETURN skill, avg_sal, job_count ORDER BY avg_sal DESC LIMIT 100"),
                    return_exceptions=True
                )
                cache_set("trend", {"success": True, "data": {
                    "hot_skills":            [dict(r) for r in (hot_r   if isinstance(hot_r,   list) else [])],
                    "category_distribution": [dict(r) for r in (cat_r   if isinstance(cat_r,   list) else [])],
                    "skill_combos":          [dict(r) for r in (combo_r if isinstance(combo_r, list) else [])],
                    "high_salary_skills":    [{"skill": r["skill"], "avg_salary_k": round(r["avg_sal"] or 0, 1), "job_count": r["job_count"]} for r in (sal_r if isinstance(sal_r, list) else [])],
                }}, ttl=600)
            except Exception as e:
                logger.warning(f"  âš ï¸ trend åˆ·æ–°å¤±è´¥: {e}")

            # â”€â”€ graphï¼ˆé»˜è®¤å‚æ•°å¹¶å‘ï¼‰â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            try:
                n_rows, e_rows = await asyncio.gather(
                    _neo4j_query("MATCH (s:Skill) WHERE coalesce(s.demand_count,0) >= 5 RETURN s.name AS skill, s.category AS category, coalesce(s.demand_count,0) AS demand_count, coalesce(s.hot_score,0) AS hot_score, coalesce(s.avg_salary,0) AS avg_salary ORDER BY demand_count DESC LIMIT 100"),
                    _neo4j_query("MATCH (j:Job)-[:REQUIRES]->(s1:Skill),(j)-[:REQUIRES]->(s2:Skill) WHERE s1.name < s2.name AND coalesce(s1.demand_count,0) >= 5 AND coalesce(s2.demand_count,0) >= 5 WITH s1.name AS skill1, s2.name AS skill2, count(j) AS co_count WHERE co_count >= 1 RETURN skill1, skill2, co_count ORDER BY co_count DESC LIMIT 200"),
                    return_exceptions=True
                )
                nl = [dict(r) for r in (n_rows if isinstance(n_rows, list) else [])]
                el = [dict(r) for r in (e_rows if isinstance(e_rows, list) else [])]
                cache_set("graph:100:5:200", {"success": True, "data": {"nodes": nl, "edges": el, "node_count": len(nl), "edge_count": len(el)}}, ttl=600)
            except Exception as e:
                logger.warning(f"  âš ï¸ graph åˆ·æ–°å¤±è´¥: {e}")

        logger.info("â™»ï¸  ç¼“å­˜åˆ·æ–°å®Œæˆ")
        await asyncio.sleep(270)  # æ¯ 4.5 åˆ†é’Ÿåˆ·æ–°ä¸€æ¬¡


# ===== è·¯ç”±æ³¨å†Œ =====

# æ³¨å†Œè®¤è¯ç›¸å…³è·¯ç”±
include_auth_routes(app)


@app.on_event("shutdown")
async def shutdown_event():
    """å…³é—­æ—¶æ¸…ç†èµ„æº"""
    logger.info("å…³é—­APIæœåŠ¡...")
    if agent is not None:
        agent.close()
    if neo4j_manager is not None:
        neo4j_manager.close()


# ===== APIç«¯ç‚¹ =====

@app.get("/")
async def root():
    """æ ¹è·¯å¾„"""
    return {
        "message": "æ™ºèƒ½æ‹›è˜åˆ†æAPI v2.0",
        "status": "running",
        "features": [
            "RAGè¯­ä¹‰æœç´¢",
            "æŠ€èƒ½å·®è·åˆ†æ",
            "å²—ä½æ¨è",
            "Agentå¯¹è¯",
            "æ··åˆæŠ€èƒ½æŠ½å–"
        ],
        "docs": "/docs"
    }


@app.get("/api/health/quick")
async def health_quick():
    """è½»é‡å¥åº·æ£€æŸ¥ â€”â€” ä»…è¿”å›æœåŠ¡åˆå§‹åŒ–çŠ¶æ€ï¼Œ<10msï¼Œä¾›ç›‘æ§çœ‹æ¿ä½¿ç”¨"""
    return {
        "status": "ok",
        "ts": time.time(),
        "services": {
            "rag":    rag_service is not None,
            "agent":  agent is not None,
            "neo4j":  neo4j_manager is not None,
            "search": skill_extractor is not None,
        },
        "cache_size": len(_api_cache),
    }


@app.get("/api/health")
async def health_check():
    """å¥åº·æ£€æŸ¥"""
    return {
        "status": "healthy",
        "services": {
            "rag": rag_service is not None,
            "agent": agent is not None,
            "skill_extractor": skill_extractor is not None,
            "neo4j": neo4j_manager is not None,
        }
    }


@app.post("/api/skill/extract")
async def extract_skills(request: SkillExtractRequest):
    """
    æŠ€èƒ½æŠ½å–ï¼ˆæ··åˆæ–¹æ³•ï¼‰
    
    ä½¿ç”¨è§„åˆ™+LLMæ··åˆæ–¹æ³•ä»å²—ä½ä¿¡æ¯ä¸­æŠ½å–æŠ€èƒ½
    """
    if not skill_extractor:
        raise HTTPException(status_code=503, detail="æŠ€èƒ½æŠ½å–æœåŠ¡ä¸å¯ç”¨")
    
    try:
        # æ„å»ºå²—ä½æ•°æ®
        job_data = {
            'title': request.title,
            'skills': request.explicit_skills,
            'jd_text': request.jd_text
        }
        
        # æŠ½å–æŠ€èƒ½
        result = skill_extractor.extract(job_data, use_llm=request.use_llm)
        
        # ç®€åŒ–è¿”å›ç»“æœ
        return {
            "success": True,
            "data": {
                "skills": [s['name'] for s in result['merged_skills']],
                "detailed": result['merged_skills'],
                "stats": result['stats'],
                "method": result['method']
            }
        }
    except Exception as e:
        logger.error(f"æŠ€èƒ½æŠ½å–å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/rag/search")
async def rag_search(request: SearchRequest):
    """
    RAGè¯­ä¹‰æœç´¢

    ä½¿ç”¨å‘é‡æ£€ç´¢+LLMæ€»ç»“çš„æ–¹å¼æœç´¢ç›¸å…³å²—ä½ã€‚
    è‹¥ Neo4j å¯ç”¨ï¼Œè‡ªåŠ¨å›å¡«å„å²—ä½çš„å®Œæ•´æŠ€èƒ½åˆ—è¡¨ï¼ˆæ— éœ€é‡å»ºå‘é‡åº“ï¼‰ã€‚
    ç»“æœç¼“å­˜ 2 åˆ†é’Ÿï¼ŒåŒä¸€å…³é”®è¯çš„é‡å¤è¯·æ±‚ï¼ˆåŒ…æ‹¬å¥åº·æ£€æŸ¥ï¼‰ç›´æ¥å‘½ä¸­ç¼“å­˜ã€‚
    """
    if not rag_service:
        raise HTTPException(status_code=503, detail="RAGæœåŠ¡ä¸å¯ç”¨")

    # ç¼“å­˜ï¼šåŒä¸€ (query, city, top_k) ç»„åˆ 2 åˆ†é’Ÿå†…ä¸é‡å¤è·‘å‘é‡æ¨æ–­
    rag_cache_key = f"rag:{request.query}:{request.city}:{request.top_k}"
    cached = cache_get(rag_cache_key)
    if cached:
        return cached

    try:
        filters = {"city": request.city} if request.city else None

        # search_and_summarize æ˜¯åŒæ­¥é˜»å¡ï¼ˆChromaDB + å¯èƒ½è°ƒ LLMï¼‰ï¼Œæ”¾å…¥çº¿ç¨‹æ± 
        result = await asyncio.to_thread(
            rag_service.search_and_summarize,
            request.query,
            request.top_k,
            filters,
        )

        # ç”¨ Neo4j æ‰¹é‡å›å¡«æŠ€èƒ½ï¼ˆå‘é‡åº“å…ƒæ•°æ®ä¸ä¸€å®šæœ‰ skills å­—æ®µï¼ŒNeo4j æ˜¯æƒå¨æ¥æºï¼‰
        jobs = result.get("retrieved_jobs", [])
        if jobs and neo4j_manager:
            try:
                job_ids = [j["job_id"] for j in jobs if j.get("job_id")]
                if job_ids:
                    cypher = """
                    MATCH (j:Job)-[:REQUIRES]->(s:Skill)
                    WHERE j.job_id IN $job_ids
                    RETURN j.job_id AS job_id, collect(s.name) AS skills
                    """
                    rows = await _neo4j_query(cypher, {"job_ids": job_ids})
                    skills_map = {r["job_id"]: r["skills"] for r in rows}
                    for job in jobs:
                        neo4j_skills = skills_map.get(job["job_id"])
                        if neo4j_skills:
                            job["skills"] = neo4j_skills
            except Exception as e:
                logger.warning(f"Neo4j æŠ€èƒ½å›å¡«å¤±è´¥ï¼ˆä¸å½±å“æœç´¢ç»“æœï¼‰: {e}")

        final = {"success": True, "data": result}
        cache_set(rag_cache_key, final, ttl=120)  # ç¼“å­˜ 2 åˆ†é’Ÿ
        return final
    except Exception as e:
        logger.error(f"RAGæœç´¢å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/skill/gap-analysis")
async def skill_gap_analysis(request: SkillGapRequest):
    """
    æŠ€èƒ½å·®è·åˆ†æ
    
    åˆ†æç”¨æˆ·æŠ€èƒ½ä¸ç›®æ ‡å²—ä½çš„å·®è·ï¼Œæä¾›å­¦ä¹ å»ºè®®
    """
    if not rag_service:
        raise HTTPException(status_code=503, detail="RAGæœåŠ¡ä¸å¯ç”¨")
    
    try:
        result = rag_service.skill_gap_analysis(
            user_skills=request.user_skills,
            target_position=request.target_position,
            city=request.city
        )
        
        return {
            "success": True,
            "data": result
        }
    except Exception as e:
        logger.error(f"æŠ€èƒ½å·®è·åˆ†æå¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/job/recommend")
async def recommend_jobs(request: RecommendRequest):
    """
    å²—ä½æ¨è
    
    åŸºäºç”¨æˆ·æŠ€èƒ½æ¨èåˆé€‚çš„å²—ä½
    """
    if not rag_service:
        raise HTTPException(status_code=503, detail="RAGæœåŠ¡ä¸å¯ç”¨")
    
    try:
        # æ„å»ºè¿‡æ»¤æ¡ä»¶
        filters = {"city": request.city} if request.city else None
        
        result = rag_service.recommend_jobs(
            user_skills=request.user_skills,
            top_k=request.top_k,
            filters=filters
        )
        
        return {
            "success": True,
            "data": result
        }
    except Exception as e:
        logger.error(f"å²—ä½æ¨èå¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/agent/chat")
async def agent_chat(request: AgentChatRequest):
    """
    Agentå¯¹è¯ï¼ˆéæµå¼ï¼Œå…¼å®¹æ—§å®¢æˆ·ç«¯ï¼‰

    ä¸æ™ºèƒ½Agentè¿›è¡Œå¤šè½®å¯¹è¯ï¼Œè¿”å›å®Œæ•´å“åº”ã€‚
    æ³¨æ„ï¼šä½¿ç”¨ run_in_executor é¿å…åŒæ­¥è°ƒç”¨é˜»å¡ asyncio äº‹ä»¶å¾ªç¯ã€‚
    """
    # å¥åº·æ£€æŸ¥ä¸“ç”¨ ping å¿«é€Ÿè·¯å¾„ï¼Œ<5ms è¿”å›ï¼Œä¸æ¶ˆè€— LLM è°ƒç”¨
    if request.message.strip().lower() in ("ping", "__ping__", "health"):
        return {
            "success": True,
            "data": {
                "response": "pong",
                "session_id": request.session_id or "ping",
                "agent_ready": agent is not None,
            },
        }

    if not agent:
        raise HTTPException(status_code=503, detail="AgentæœåŠ¡ä¸å¯ç”¨")

    try:
        session_id = request.session_id or str(uuid.uuid4())
        # agent.chat() æ˜¯åŒæ­¥é˜»å¡è°ƒç”¨ï¼Œå¿…é¡»æ”¾å…¥çº¿ç¨‹æ± ï¼Œå¦åˆ™ä¼šå¡ä½æ•´ä¸ªäº‹ä»¶å¾ªç¯
        loop = asyncio.get_event_loop()
        response = await loop.run_in_executor(
            None, agent.chat, request.message, session_id
        )
        return {
            "success": True,
            "data": {
                "response": response,
                "session_id": session_id
            }
        }
    except Exception as e:
        logger.error(f"Agentå¯¹è¯å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/agent/chat/stream")
async def agent_chat_stream(request: AgentChatRequest):
    """
    Agentæµå¼å¯¹è¯ï¼ˆSSEï¼Œæ¨èä½¿ç”¨ï¼‰

    é€šè¿‡ Server-Sent Events é€ token æ¨é€å“åº”ï¼Œç”¨æˆ·å¯ç«‹å³çœ‹åˆ°å†…å®¹ç”Ÿæˆè¿‡ç¨‹ã€‚

    äº‹ä»¶æ ¼å¼ï¼š
    - data: <token>      â€”â€” æ™®é€šæ–‡æœ¬ token
    - event: status      â€”â€” å·¥å…·è°ƒç”¨çŠ¶æ€æç¤ºï¼ˆå¦‚"æ­£åœ¨æ£€ç´¢å²—ä½..."ï¼‰
    - data: [DONE]       â€”â€” æµç»“æŸæ ‡å¿—
    - event: error       â€”â€” å‡ºé”™æ—¶çš„é”™è¯¯ä¿¡æ¯
    """
    if not agent:
        raise HTTPException(status_code=503, detail="AgentæœåŠ¡ä¸å¯ç”¨")

    session_id = request.session_id or str(uuid.uuid4())

    async def event_generator():
        # å…ˆæ¨é€ session_idï¼Œä¾›å‰ç«¯è®°å½•
        yield f"event: session\ndata: {session_id}\n\n"
        async for chunk in agent.async_chat_stream(request.message, session_id, mode=request.mode):
            yield chunk

    return StreamingResponse(
        event_generator(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "X-Accel-Buffering": "no",   # ç¦æ­¢ Nginx ç¼“å†²ï¼Œç¡®ä¿å®æ—¶æ¨é€
        },
    )


@app.get("/api/stats")
async def get_stats():
    """è·å–ç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯"""
    cached = cache_get("stats")
    if cached:
        return cached
    try:
        stats = {}
        if rag_service:
            stats['rag'] = await asyncio.to_thread(rag_service.vector_db.get_stats)
        try:
            stats['neo4j'] = await asyncio.to_thread(neo4j_manager.get_database_stats) if neo4j_manager else None
        except Exception:
            stats['neo4j'] = None
        result = {"success": True, "data": stats}
        cache_set("stats", result, ttl=300)
        return result
    except Exception as e:
        logger.error(f"è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


# ===== å›¾è°±å¢å¼ºæ¥å£ =====

@app.post("/api/search")
async def graph_search(request: GraphSearchRequest):
    """
    è¯­ä¹‰åŒ–æœç´¢ï¼ˆå›¾è°±å¢å¼ºç‰ˆï¼‰

    æµç¨‹ï¼š
    1. ç”¨æŠ€èƒ½è¯å…¸å°†æŸ¥è¯¢è¯æ˜ å°„åˆ°æ ‡å‡†æŠ€èƒ½å
    2. é€šè¿‡ Neo4j å›¾éå†æ‰¾åˆ°éœ€è¦è¿™äº›æŠ€èƒ½çš„å²—ä½
    3. è‹¥ Neo4j ä¸å¯ç”¨åˆ™è‡ªåŠ¨é™çº§ä¸ºå‘é‡æ£€ç´¢
    """
    if not skill_extractor and not rag_service:
        raise HTTPException(status_code=503, detail="æœç´¢æœåŠ¡ä¸å¯ç”¨")

    # ç»Ÿä¸€ç”¨å®é™…ç”Ÿæ•ˆçš„ limit å€¼ä½œä¸º cache keyï¼Œé¿å… top_k=None å’Œ top_k=500 å‘½ä¸­ä¸åŒç¼“å­˜
    _effective_limit = min(request.top_k, 500) if request.top_k else 500
    cache_key = f"search:{request.query}:{request.city}:{_effective_limit}"
    cached = cache_get(cache_key)
    if cached:
        return cached

    try:
        matched_skills = []

        # Step 1ï¼šæŠ€èƒ½è¯å…¸æ˜ å°„ï¼ˆCPU å¯†é›†å‹å­—å…¸æ‰«æï¼Œæ”¾å…¥çº¿ç¨‹æ± é¿å…é˜»å¡äº‹ä»¶å¾ªç¯ï¼‰
        if skill_extractor:
            def _extract():
                job_data = {'title': request.query, 'jd_text': request.query, 'skills': []}
                return skill_extractor.extract(job_data, use_llm=False)
            extract_result = await asyncio.to_thread(_extract)
            matched_skills = [s['name'] for s in extract_result.get('merged_skills', [])]

        # Step 2ï¼šNeo4j å›¾è°±æŸ¥è¯¢
        graph_jobs = []
        search_type = "skill"   # "skill" | "title"
        if neo4j_manager:
            # ç»“æœä¸Šé™ï¼šå¤–éƒ¨æ˜ç¡®æŒ‡å®šæ—¶éµä»ï¼Œå¦åˆ™é»˜è®¤ 500ï¼ˆå…¨åº“æ£€ç´¢åå–å‰ 500 æ¡ï¼‰
            # ç›‘æ§å¥åº·æ£€æŸ¥ä¼  top_k=1ï¼Œä¸å—å½±å“ï¼›å‰ç«¯ä¸ä¼  top_k åˆ™å– 500 æ¡
            limit_val = min(request.top_k, 500) if request.top_k else 500

            if matched_skills:
                # 2aï¼šæŠ€èƒ½æœç´¢ â€”â€” ä» Skill èŠ‚ç‚¹ï¼ˆå·²å»ºç´¢å¼•ï¼‰å‡ºå‘éå† Jobï¼Œæ•ˆç‡æœ€é«˜
                # ç¬¬ä¸€æ­¥ï¼šåˆ©ç”¨ Skill.name ç´¢å¼•å¿«é€Ÿå®šä½æ‰€æœ‰åŒ¹é…å²—ä½ï¼ŒæŒ‰å‘½ä¸­æŠ€èƒ½æ•°æ’åº
                # ç¬¬äºŒæ­¥ï¼šä»…å¯¹ top-500 ç»“æœå†æŸ¥ä¸€æ¬¡ all_skillsï¼Œé¿å…å¯¹å…¨åº“åšäºŒæ¬¡æ‰«æ
                search_type = "skill"
                cypher = f"""
                MATCH (j:Job)-[:REQUIRES]->(s:Skill)
                WHERE s.name IN $skill_names
                  AND ($city IS NULL OR j.city = $city)
                WITH j,
                     collect(DISTINCT s.name) AS matched_skills,
                     count(DISTINCT s)        AS match_count
                ORDER BY match_count DESC, j.salary_max DESC
                LIMIT {limit_val}
                MATCH (j)-[:REQUIRES]->(all_s:Skill)
                WITH j, matched_skills, match_count,
                     count(DISTINCT all_s) AS total_skills
                OPTIONAL MATCH (j)-[:POSTED_BY]->(c:Company)
                RETURN j.job_id          AS job_id,
                       j.title           AS title,
                       j.city            AS city,
                       coalesce(c.name, '') AS company,
                       coalesce(j.salary_min, 0) AS salary_min,
                       coalesce(j.salary_max, 0) AS salary_max,
                       coalesce(j.experience,    '') AS experience,
                       coalesce(j.education,     '') AS education,
                       coalesce(j.jd_text,       '') AS jd_text,
                       coalesce(j.publish_date,  '') AS publish_date,
                       matched_skills,
                       match_count,
                       total_skills
                """
                rows = await _neo4j_query(cypher, {
                    "skill_names": matched_skills,
                    "city": request.city,
                })
            else:
                # 2bï¼šèŒä½åç§°å…³é”®è¯æœç´¢ï¼ˆæ— æŠ€èƒ½è¯æ—¶ï¼‰
                # è‹¥ Neo4j å·²å»ºå…¨æ–‡ç´¢å¼• job_title_ftsï¼Œæ­¤æŸ¥è¯¢å¯åœ¨æ¯«ç§’çº§å®Œæˆ
                search_type = "title"
                raw_keywords = [w for w in request.query.replace('ï¼Œ', ' ').replace(',', ' ').split() if len(w) >= 2]
                if not raw_keywords:
                    raw_keywords = [request.query]
                # å»æ‰å•å¼•å·é˜²æ­¢ Cypher æ³¨å…¥ï¼›é™åˆ¶æœ€å¤š 5 ä¸ªå…³é”®è¯
                keywords = [kw.replace("'", "") for kw in raw_keywords[:5]]
                # å‚æ•°åŒ–å†™æ³•ï¼š$kw0, $kw1... æ›¿ä»£å­—ç¬¦ä¸²æ‹¼æ¥ï¼Œå½»åº•æ¶ˆé™¤æ³¨å…¥é£é™©
                kw_params = {f"kw{i}": kw for i, kw in enumerate(keywords)}
                where_parts = " OR ".join([f"j.title CONTAINS $kw{i}" for i in range(len(keywords))])
                score_parts = " + ".join([f"(CASE WHEN j.title CONTAINS $kw{i} THEN 1 ELSE 0 END)" for i in range(len(keywords))])
                cypher = f"""
                MATCH (j:Job)
                WHERE ({where_parts})
                  AND ($city IS NULL OR j.city = $city)
                WITH j, ({score_parts}) AS kw_score
                ORDER BY kw_score DESC, j.salary_max DESC
                LIMIT $limit_val
                OPTIONAL MATCH (j)-[:REQUIRES]->(s:Skill)
                WITH j, kw_score, collect(DISTINCT s.name) AS all_skills
                OPTIONAL MATCH (j)-[:POSTED_BY]->(c:Company)
                RETURN j.job_id          AS job_id,
                       j.title           AS title,
                       j.city            AS city,
                       coalesce(c.name, '') AS company,
                       coalesce(j.salary_min, 0) AS salary_min,
                       coalesce(j.salary_max, 0) AS salary_max,
                       coalesce(j.experience,    '') AS experience,
                       coalesce(j.education,     '') AS education,
                       coalesce(j.jd_text,       '') AS jd_text,
                       coalesce(j.publish_date,  '') AS publish_date,
                       all_skills        AS matched_skills,
                       kw_score          AS match_count,
                       size(all_skills)  AS total_skills
                """
                rows = await _neo4j_query(cypher, {"city": request.city, "limit_val": limit_val, **kw_params})

            for r in rows:
                graph_jobs.append({
                    "job_id":        r["job_id"],
                    "title":         r["title"],
                    "city":          r["city"],
                    "company":       r["company"],
                    "salary_range":  f"{r['salary_min'] or 0}-{r['salary_max'] or 0}K",
                    "experience":    r.get("experience", ""),
                    "education":     r.get("education", ""),
                    "jd_text":        r.get("jd_text", ""),
                    "publish_date":   r.get("publish_date", ""),
                    "matched_skills": r["matched_skills"],
                    "match_count":   r["match_count"],
                    "total_skills":  r["total_skills"],
                    "search_type":   search_type,
                    "source":        "graph",
                })

        # Step 3ï¼šå‘é‡è¯­ä¹‰è¡¥å……ï¼ˆå¯é€‰ï¼Œé»˜è®¤å…³é—­ä»¥åŠ é€Ÿå“åº”ï¼‰
        vector_jobs = []
        need_vector = request.include_vector or (not graph_jobs and rag_service)
        if need_vector and rag_service:
            filters = {"city": request.city} if request.city else None
            v_result = rag_service.search_and_summarize(
                query=request.query, top_k=request.top_k, filters=filters
            )
            for j in v_result.get("retrieved_jobs", []):
                j["source"] = "vector"
                vector_jobs.append(j)

        # åˆå¹¶å»é‡ï¼šå›¾è°±ç»“æœä¼˜å…ˆï¼Œå‘é‡ç»“æœè¡¥è¶³
        seen_ids = {j["job_id"] for j in graph_jobs}
        merged = graph_jobs[:]
        for j in vector_jobs:
            if j["job_id"] not in seen_ids:
                merged.append(j)
                seen_ids.add(j["job_id"])

        # æœ€ç»ˆæˆªæ–­ï¼šå¤–éƒ¨æ˜ç¡®ä¼ äº† top_k åˆ™éµä»ï¼Œå¦åˆ™ç»Ÿä¸€ä¸Šé™ 500
        final_limit = min(request.top_k, 500) if request.top_k else 500
        merged = merged[:final_limit]

        result = {
            "success": True,
            "data": {
                "jobs": merged,
                "count": len(merged),
                "query": request.query,
                "matched_skills": matched_skills,
                "graph_hits": len(graph_jobs),
                "vector_hits": len(vector_jobs),
            },
        }
        cache_set(cache_key, result, ttl=180)   # æœç´¢ç»“æœç¼“å­˜ 3 åˆ†é’Ÿ
        return result
    except Exception as e:
        logger.error(f"å›¾è°±æœç´¢å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/recommend")
async def graph_recommend(request: GraphRecommendRequest):
    """
    æ™ºèƒ½å²—ä½æ¨èï¼ˆCypher ç²¾å‡†åŒ¹é… + è¯­ä¹‰æ‰©å±•ï¼‰

    æµç¨‹ï¼š
    1. Cypher ç²¾å‡†åŒ¹é…ï¼šæŸ¥æ‰¾éœ€è¦ç”¨æˆ·æŠ€èƒ½æœ€å¤šçš„å²—ä½
    2. å›¾è°±æ‰©å±•ï¼šé€šè¿‡ RELATED_TO å…³ç³»æ‰¾å…³è”æŠ€èƒ½ï¼Œæ‰©å¤§æ¨èèŒƒå›´
    3. é™çº§ï¼šNeo4j ä¸å¯ç”¨æ—¶é€€å›å‘é‡æ¨è
    """
    if not rag_service and not neo4j_manager:
        raise HTTPException(status_code=503, detail="æ¨èæœåŠ¡ä¸å¯ç”¨")

    skills_key = ",".join(sorted(request.user_skills or []))
    cache_key = f"recommend:{skills_key}:{request.city}:{request.top_k}"
    cached = cache_get(cache_key)
    if cached:
        return cached

    try:
        precise_jobs = []
        expanded_jobs = []
        related_skills: List[str] = []

        if neo4j_manager and request.user_skills:
            rec_limit = min(request.top_k, 500) if request.top_k else 500

            # Step 1 & 2ï¼šç²¾å‡†åŒ¹é… + å…³è”æŠ€èƒ½æ‰©å±• å¹¶å‘æ‰§è¡Œ
            precise_cypher = """
            MATCH (j:Job)-[:REQUIRES]->(s:Skill)
            WHERE s.name IN $user_skills
              AND ($city IS NULL OR j.city = $city)
            WITH j,
                 collect(DISTINCT s.name) AS matched_skills,
                 count(DISTINCT s)        AS match_count
            ORDER BY match_count DESC
            LIMIT $top_k
            MATCH (j)-[:REQUIRES]->(all_s:Skill)
            WITH j, matched_skills, match_count,
                 count(DISTINCT all_s) AS total_skills
            OPTIONAL MATCH (j)-[:POSTED_BY]->(c:Company)
            RETURN j.job_id     AS job_id,
                   j.title      AS title,
                   j.city       AS city,
                   coalesce(c.name, '') AS company,
                   j.salary_min AS salary_min,
                   j.salary_max AS salary_max,
                   matched_skills,
                   match_count,
                   total_skills
            """
            expand_cypher = """
            MATCH (us:Skill)-[:RELATED_TO]-(rs:Skill)
            WHERE us.name IN $user_skills
              AND NOT rs.name IN $user_skills
            RETURN DISTINCT rs.name AS related_skill
            LIMIT 10
            """
            precise_rows, rel_rows = await asyncio.gather(
                _neo4j_query(precise_cypher, {
                    "user_skills": request.user_skills,
                    "city": request.city,
                    "top_k": rec_limit,
                }),
                _neo4j_query(expand_cypher, {"user_skills": request.user_skills}),
                return_exceptions=True,
            )
            if isinstance(precise_rows, Exception):
                logger.warning(f"ç²¾å‡†æ¨èæŸ¥è¯¢å¤±è´¥: {precise_rows}")
                precise_rows = []
            if isinstance(rel_rows, Exception):
                logger.warning(f"å…³è”æŠ€èƒ½æŸ¥è¯¢å¤±è´¥: {rel_rows}")
                rel_rows = []

            for r in precise_rows:
                precise_jobs.append({
                    "job_id": r["job_id"],
                    "title": r["title"],
                    "city": r["city"],
                    "company": r["company"],
                    "salary_range": f"{r['salary_min'] or 0}-{r['salary_max'] or 0}K",
                    "matched_skills": r["matched_skills"],
                    "match_count": r["match_count"],
                    "total_skills": r["total_skills"],
                    "match_type": "precise",
                })

            related_skills = [r["related_skill"] for r in rel_rows]

            if related_skills:
                cypher_expanded = """
                MATCH (j:Job)-[:REQUIRES]->(s:Skill)
                WHERE s.name IN $related_skills
                  AND ($city IS NULL OR j.city = $city)
                WITH j,
                     collect(DISTINCT s.name) AS expansion_skills,
                     count(DISTINCT s)        AS exp_count
                ORDER BY exp_count DESC
                LIMIT $top_k
                OPTIONAL MATCH (j)-[:POSTED_BY]->(c:Company)
                RETURN j.job_id     AS job_id,
                       j.title      AS title,
                       j.city       AS city,
                       coalesce(c.name, '') AS company,
                       j.salary_min AS salary_min,
                       j.salary_max AS salary_max,
                       expansion_skills,
                       exp_count
                """
                exp_rows = await _neo4j_query(cypher_expanded, {
                    "related_skills": related_skills,
                    "city": request.city,
                    "top_k": rec_limit,
                })
                for r in exp_rows:
                    expanded_jobs.append({
                        "job_id": r["job_id"],
                        "title": r["title"],
                        "city": r["city"],
                        "company": r["company"],
                        "salary_range": f"{r['salary_min'] or 0}-{r['salary_max'] or 0}K",
                        "matched_skills": r["expansion_skills"],
                        "match_count": r["exp_count"],
                        "match_type": "expanded",
                    })

        # å‘é‡å…œåº•
        vector_jobs = []
        if rag_service and not precise_jobs:
            filters = {"city": request.city} if request.city else None
            v_result = rag_service.recommend_jobs(
                user_skills=request.user_skills,
                top_k=request.top_k,
                filters=filters,
            )
            for j in v_result.get("retrieved_jobs", []):
                j["match_type"] = "vector"
                vector_jobs.append(j)

        # åˆå¹¶ï¼šç²¾å‡† > æ‰©å±• > å‘é‡
        seen_ids: set = set()
        merged: List[Dict] = []
        for j in precise_jobs + expanded_jobs + vector_jobs:
            if j["job_id"] not in seen_ids:
                merged.append(j)
                seen_ids.add(j["job_id"])

        # top_k ä¸º None æ—¶ list[:None] ç­‰äº list[:]ï¼ˆå…¨é‡ï¼‰ï¼Œä¸ä¼šæˆªæ–­
        merge_limit = min(request.top_k, 500) if request.top_k else 500
        merged = merged[:merge_limit]

        result = {
            "success": True,
            "data": {
                "jobs": merged,
                "count": len(merged),
                "precise_count": len(precise_jobs),
                "expanded_count": len(expanded_jobs),
                "related_skills": related_skills,
            },
        }
        cache_set(cache_key, result, ttl=180)   # æ¨èç»“æœç¼“å­˜ 3 åˆ†é’Ÿ
        return result
    except Exception as e:
        logger.error(f"å›¾è°±æ¨èå¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/gap-analysis")
async def graph_gap_analysis(request: GraphGapAnalysisRequest):
    """
    æŠ€èƒ½å·®è·åˆ†æï¼ˆå›¾è°±ç‰ˆï¼‰

    æµç¨‹ï¼š
    1. ä» Neo4j ä¸­æŸ¥æ‰¾ç›®æ ‡å²—ä½æ‰€éœ€çš„é«˜é¢‘æŠ€èƒ½
    2. ä¸ç”¨æˆ·æŠ€èƒ½å¯¹æ¯”ï¼Œè®¡ç®—åŒ¹é…ç‡å’Œç¼ºå¤±æŠ€èƒ½
    3. é€šè¿‡å›¾è°±æŸ¥è¯¢ç¼ºå¤±æŠ€èƒ½çš„å‰ç½®/å…³è”æŠ€èƒ½ï¼Œç”Ÿæˆå­¦ä¹ è·¯å¾„
    """
    if not neo4j_manager and not rag_service:
        raise HTTPException(status_code=503, detail="åˆ†ææœåŠ¡ä¸å¯ç”¨")

    user_key = ",".join(sorted(request.user_skills or []))
    cache_key = f"gap:{request.target_position}:{user_key}"
    cached = cache_get(cache_key)
    if cached:
        return cached

    try:
        required_skills: List[str] = []
        sample_jobs: List[Dict] = []

        if neo4j_manager:
            # Step 1 & 2ï¼šé«˜é¢‘æŠ€èƒ½ + æ ·æœ¬å²—ä½ å¹¶å‘æŸ¥è¯¢ï¼ˆç‹¬ç«‹æŸ¥è¯¢ï¼Œæ— ä¾èµ–å…³ç³»ï¼‰
            req_params = {"position": request.target_position, "city": request.city}
            skill_rows, job_rows = await asyncio.gather(
                _neo4j_query("""
                    MATCH (j:Job)-[:REQUIRES]->(s:Skill)
                    WHERE j.title CONTAINS $position
                      AND ($city IS NULL OR j.city = $city)
                    WITH s.name AS skill_name, count(j) AS freq
                    ORDER BY freq DESC LIMIT 20
                    RETURN skill_name, freq
                """, req_params),
                _neo4j_query("""
                    MATCH (j:Job)
                    WHERE j.title CONTAINS $position
                      AND ($city IS NULL OR j.city = $city)
                    OPTIONAL MATCH (j)-[:POSTED_BY]->(c:Company)
                    RETURN j.job_id AS job_id, j.title AS title, j.city AS city,
                           coalesce(c.name, '') AS company,
                           j.salary_min AS salary_min, j.salary_max AS salary_max
                    LIMIT 5
                """, req_params),
                return_exceptions=True,
            )
            if isinstance(skill_rows, Exception):
                logger.warning(f"gap-analysis æŠ€èƒ½æŸ¥è¯¢å¤±è´¥: {skill_rows}")
                skill_rows = []
            if isinstance(job_rows, Exception):
                logger.warning(f"gap-analysis æ ·æœ¬å²—ä½æŸ¥è¯¢å¤±è´¥: {job_rows}")
                job_rows = []
            required_skills = [r["skill_name"] for r in skill_rows]
            sample_jobs = [{
                "title": r["title"],
                "city": r["city"],
                "company": r["company"],
                "salary_range": f"{r['salary_min'] or 0}-{r['salary_max'] or 0}K",
            } for r in job_rows]

        # è‹¥å›¾è°±æ— æ•°æ®ï¼Œç”¨å‘é‡æœç´¢å…œåº•
        if not required_skills:
            if rag_service:
                v_result = rag_service.skill_gap_analysis(
                    user_skills=request.user_skills,
                    target_position=request.target_position,
                    city=request.city,
                )
                return {"success": True, "data": v_result}
            else:
                raise HTTPException(
                    status_code=404,
                    detail=f"å›¾è°±ä¸­æœªæ‰¾åˆ°ä¸ã€Œ{request.target_position}ã€ç›¸å…³çš„å²—ä½ï¼Œè¯·å°è¯•æ›´é€šç”¨çš„å²—ä½åç§°",
                )

        # Step 2ï¼šè®¡ç®—åŒ¹é… / ç¼ºå¤±æŠ€èƒ½
        user_set = set(request.user_skills)
        required_set = set(required_skills)
        matched_skills = sorted(user_set & required_set)
        missing_skills = sorted(required_set - user_set)
        match_rate = round(len(matched_skills) / len(required_set), 3) if required_set else 0.0

        # Step 3ï¼šä¸ºç¼ºå¤±æŠ€èƒ½æŸ¥æ‰¾å­¦ä¹ è·¯å¾„ï¼ˆå‰ç½® / å…³è”æŠ€èƒ½ï¼‰
        learning_path: List[Dict] = []
        if neo4j_manager and missing_skills:
            top_missing = missing_skills[:10]
            # OPTIONAL MATCH ç¡®ä¿æ²¡æœ‰ RELATED_TO çš„æŠ€èƒ½ä¹Ÿä¼šå‡ºç°åœ¨ç»“æœä¸­
            cypher_path = """
            UNWIND $missing AS miss_name
            MATCH (ms:Skill {name: miss_name})
            OPTIONAL MATCH (ms)-[:RELATED_TO]-(pre:Skill)
            RETURN miss_name,
                   collect(DISTINCT pre.name) AS prerequisites
            """
            path_rows = await _neo4j_query(cypher_path, {"missing": top_missing})
            covered = set()
            for r in path_rows:
                prereqs = [p for p in r.get("prerequisites", []) if p]
                owned = [p for p in prereqs if p in user_set]
                needed = [p for p in prereqs if p not in user_set]
                learning_path.append({
                    "skill": r["miss_name"],
                    "owned_prerequisites": owned,
                    "needed_prerequisites": needed,
                    "ready_to_learn": len(needed) == 0,
                })
                covered.add(r["miss_name"])
            # è¡¥å……åœ¨å›¾è°±ä¸­æ‰¾ä¸åˆ°èŠ‚ç‚¹çš„æŠ€èƒ½ï¼ˆç›´æ¥å¯å­¦ä¹ ï¼‰
            for skill in top_missing:
                if skill not in covered:
                    learning_path.append({
                        "skill": skill,
                        "owned_prerequisites": [],
                        "needed_prerequisites": [],
                        "ready_to_learn": True,
                    })
            # ä¼˜å…ˆå±•ç¤º"å¯ç›´æ¥å­¦ä¹ "çš„æŠ€èƒ½
            learning_path.sort(key=lambda x: (not x["ready_to_learn"]))

        result = {
            "success": True,
            "data": {
                "target_position": request.target_position,
                "user_skills": request.user_skills,
                "required_skills": required_skills,
                "matched_skills": matched_skills,
                "missing_skills": missing_skills,
                "match_rate": match_rate,
                "learning_path": learning_path,
                "sample_jobs": sample_jobs,
            },
        }
        cache_set(cache_key, result, ttl=300)   # å·®è·åˆ†æç¼“å­˜ 5 åˆ†é’Ÿ
        return result
    except Exception as e:
        logger.error(f"å›¾è°±å·®è·åˆ†æå¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/trend")
async def market_trend():
    """
    å¸‚åœºè¶‹åŠ¿åˆ†æ

    è¿”å›ï¼š
    - çƒ­é—¨æŠ€èƒ½ TOP 20ï¼ˆæŒ‰éœ€æ±‚é‡æ’åºï¼‰
    - æŠ€èƒ½åˆ†ç±»åˆ†å¸ƒï¼ˆç¼–ç¨‹è¯­è¨€ / æ¡†æ¶ / å·¥å…·ç­‰ï¼‰
    - æŠ€èƒ½ç»„åˆå¼ºåº¦ TOP 10ï¼ˆç»å¸¸åŒæ—¶å‡ºç°çš„æŠ€èƒ½å¯¹ï¼‰
    - é«˜è–ªæŠ€èƒ½ TOP 10
    """
    if not neo4j_manager:
        raise HTTPException(status_code=503, detail="Neo4jæœåŠ¡ä¸å¯ç”¨ï¼Œè¶‹åŠ¿åˆ†æéœ€è¦å›¾è°±æ•°æ®")

    cached = cache_get("trend")
    if cached:
        return cached

    try:
        # 5 ä¸ªå­æŸ¥è¯¢å¹¶å‘æ‰§è¡Œï¼Œæ—¶é—´å–å†³äºæœ€æ…¢çš„é‚£ä¸ªè€Œé 5 ä¸ªä¹‹å’Œ
        hot_rows, cat_rows, combo_rows, salary_rows, city_rows = await asyncio.gather(
            _neo4j_query("""
                MATCH (s:Skill) WHERE s.demand_count > 0
                RETURN s.name AS skill, s.category AS category,
                       s.demand_count AS demand_count, s.hot_score AS hot_score
                ORDER BY s.demand_count DESC LIMIT 100
            """),
            _neo4j_query("""
                MATCH (s:Skill) WHERE s.demand_count > 0 AND s.category IS NOT NULL
                RETURN s.category AS category, count(s) AS skill_count,
                       sum(s.demand_count) AS total_demand
                ORDER BY total_demand DESC
            """),
            _neo4j_query("""
                MATCH (j:Job)-[:REQUIRES]->(s1:Skill),(j)-[:REQUIRES]->(s2:Skill)
                WHERE s1.name < s2.name AND s1.demand_count > 100 AND s2.demand_count > 100
                WITH s1.name AS skill1, s2.name AS skill2, count(j) AS co_count
                ORDER BY co_count DESC LIMIT 10
                RETURN skill1, skill2, co_count
            """),
            _neo4j_query("""
                MATCH (j:Job)-[:REQUIRES]->(s:Skill)
                WHERE j.salary_min > 0 AND j.salary_min < 200
                WITH s.name AS skill, avg(j.salary_min) AS avg_sal, count(j) AS job_count
                WHERE job_count >= 3
                RETURN skill, avg_sal, job_count ORDER BY avg_sal DESC LIMIT 100
            """),
            _neo4j_query("""
                MATCH (j:Job)
                WHERE j.city IS NOT NULL AND j.city <> ''
                WITH j.city AS city, count(j) AS job_count
                ORDER BY job_count DESC LIMIT 15
                RETURN city, job_count
            """),
        )
        result = {
            "success": True,
            "data": {
                "hot_skills":            [dict(r) for r in hot_rows],
                "category_distribution": [dict(r) for r in cat_rows],
                "skill_combos":          [dict(r) for r in combo_rows],
                "high_salary_skills": [
                    {"skill": r["skill"], "avg_salary_k": round(r["avg_sal"] or 0, 1), "job_count": r["job_count"]}
                    for r in salary_rows
                ],
                "city_distribution": [
                    {"city": r["city"], "job_count": r["job_count"]}
                    for r in city_rows
                ],
            },
        }
        cache_set("trend", result, ttl=600)
        return result
    except Exception as e:
        logger.error(f"è¶‹åŠ¿åˆ†æå¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/graph/categories")
async def get_skill_categories():
    """æŸ¥è¯¢ Neo4j ä¸­æ‰€æœ‰ Skill èŠ‚ç‚¹å®é™…å­˜åœ¨çš„ category å€¼"""
    if not neo4j_manager:
        raise HTTPException(status_code=503, detail="Neo4jæœåŠ¡ä¸å¯ç”¨")
    cached = cache_get("graph_categories")
    if cached:
        return cached
    rows = await _neo4j_query(
        "MATCH (s:Skill) WHERE s.category IS NOT NULL "
        "RETURN DISTINCT s.category AS category, count(s) AS cnt "
        "ORDER BY cnt DESC"
    )
    result = {"success": True, "data": [dict(r) for r in rows]}
    cache_set("graph_categories", result, ttl=3600)  # åˆ†ç±»å‡ ä¹ä¸å˜ï¼Œç¼“å­˜ 1 å°æ—¶
    return result


@app.get("/api/graph")
async def get_skill_graph(
    limit: int = Query(default=100, ge=1, le=500, description="è¿”å›æŠ€èƒ½èŠ‚ç‚¹æ•°é‡ä¸Šé™"),
    min_demand: int = Query(default=5, ge=0, description="æœ€ä½å²—ä½éœ€æ±‚æ•°è¿‡æ»¤"),
    edge_limit: int = Query(default=200, ge=0, le=5000, description="è¿”å›å…³ç³»è¾¹æ•°é‡ä¸Šé™ï¼Œ0è¡¨ç¤ºä¸è¿”å›è¾¹"),
):
    """
    æŠ€èƒ½çŸ¥è¯†å›¾è°±å¯è§†åŒ–ä¸“ç”¨æ¥å£

    è¿”å›ï¼š
    - æŠ€èƒ½èŠ‚ç‚¹åˆ—è¡¨ï¼ˆæŒ‰éœ€æ±‚é‡æ’åºï¼Œå¯é€šè¿‡ limit æ§åˆ¶æ•°é‡ï¼‰
    - æŠ€èƒ½å…±ç°å…³ç³»è¾¹åˆ—è¡¨ï¼ˆä¸¤ä¸ªæŠ€èƒ½åŒæ—¶å‡ºç°åœ¨ä¸€ä¸ªå²—ä½ä¸­ï¼‰
    """
    if not neo4j_manager:
        raise HTTPException(status_code=503, detail="Neo4jæœåŠ¡ä¸å¯ç”¨")

    cache_key = f"graph:{limit}:{min_demand}:{edge_limit}"
    cached = cache_get(cache_key)
    if cached:
        return cached

    try:
        # èŠ‚ç‚¹ä¸è¾¹æŸ¥è¯¢å¹¶å‘ï¼šè¾¹æŸ¥è¯¢ç›´æ¥ç”¨ demand_count è¿‡æ»¤ï¼Œæ— éœ€å…ˆç­‰èŠ‚ç‚¹ç»“æœ
        node_rows, edge_rows = await asyncio.gather(
            _neo4j_query("""
                MATCH (s:Skill)
                WHERE coalesce(s.demand_count, 0) >= $min_demand
                RETURN s.name AS skill, s.category AS category,
                       coalesce(s.demand_count, 0) AS demand_count,
                       coalesce(s.hot_score, 0)    AS hot_score,
                       coalesce(s.avg_salary, 0)   AS avg_salary
                ORDER BY demand_count DESC LIMIT $limit
            """, {"min_demand": min_demand, "limit": limit}),
            _neo4j_query("""
                MATCH (j:Job)-[:REQUIRES]->(s1:Skill),(j)-[:REQUIRES]->(s2:Skill)
                WHERE s1.name < s2.name
                  AND coalesce(s1.demand_count, 0) >= $min_demand
                  AND coalesce(s2.demand_count, 0) >= $min_demand
                WITH s1.name AS skill1, s2.name AS skill2, count(j) AS co_count
                WHERE co_count >= 1
                RETURN skill1, skill2, co_count
                ORDER BY co_count DESC LIMIT $edge_limit
            """, {"min_demand": min_demand, "edge_limit": edge_limit}),
            return_exceptions=True,
        )
        if isinstance(node_rows, Exception):
            raise node_rows  # èŠ‚ç‚¹æŸ¥è¯¢å¤±è´¥ç›´æ¥ä¸ŠæŠ¥
        if isinstance(edge_rows, Exception):
            logger.warning(f"å›¾è°±è¾¹æŸ¥è¯¢å¤±è´¥ï¼ˆèŠ‚ç‚¹ä»è¿”å›ï¼‰: {edge_rows}")
            edge_rows = []
        node_list = [dict(r) for r in node_rows]
        edge_list = [dict(r) for r in edge_rows]

        result = {
            "success": True,
            "data": {
                "nodes": node_list,
                "edges": edge_list,
                "node_count": len(node_list),
                "edge_count": len(edge_list),
            },
        }
        cache_set(cache_key, result, ttl=600)
        return result
    except Exception as e:
        logger.error(f"æŠ€èƒ½å›¾è°±æŸ¥è¯¢å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


# ===== å¯åŠ¨è„šæœ¬ =====

if __name__ == "__main__":
    import uvicorn
    
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    # å¯åŠ¨æœåŠ¡
    uvicorn.run(
        "main:app",
        host=api_config.get('host', '0.0.0.0'),
        port=api_config.get('port', 8000),
        reload=api_config.get('debug', True),
        log_level="info"
    )
