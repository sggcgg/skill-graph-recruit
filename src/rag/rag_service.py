"""
RAGæœåŠ¡
ç»“åˆå‘é‡æ£€ç´¢å’ŒLLMï¼Œæä¾›æ™ºèƒ½é—®ç­”å’Œåˆ†æ
"""
import logging
from typing import List, Dict, Optional
from pathlib import Path
import sys

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°path
project_root = Path(__file__).parent.parent.parent
if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))

from src.rag.vector_db import VectorDB

logger = logging.getLogger(__name__)


class RAGService:
    """
    RAGæ£€ç´¢å¢å¼ºç”ŸæˆæœåŠ¡
    
    åŠŸèƒ½:
    1. è¯­ä¹‰æœç´¢ + LLMæ€»ç»“
    2. æŠ€èƒ½å·®è·åˆ†æ
    3. å²—ä½æ¨è
    4. å­¦ä¹ è·¯å¾„è§„åˆ’
    """
    
    def __init__(self):
        """åˆå§‹åŒ–RAGæœåŠ¡"""
        logger.info("åˆå§‹åŒ–RAGæœåŠ¡...")

        # åˆå§‹åŒ–å‘é‡æ•°æ®åº“
        self.vector_db = VectorDB()

        # å»¶è¿Ÿå¯¼å…¥ï¼Œé¿å…ä¸ agent æ¨¡å—çš„å¾ªç¯ä¾èµ–
        from src.agent.qwen_api_client import QwenAPIClient

        # LLM ç»Ÿä¸€ä½¿ç”¨ Qwen APIï¼ˆæ— éœ€æœ¬åœ°æ¨¡å‹ï¼‰
        self.qwen_api = QwenAPIClient()
        if self.qwen_api.api_key:
            logger.info("âœ… Qwen API åˆå§‹åŒ–æˆåŠŸï¼ŒRAG æ‘˜è¦å·²å°±ç»ª")
        else:
            logger.warning("âš ï¸  æœªé…ç½® DASHSCOPE_API_KEYï¼ŒRAG æ‘˜è¦ä¸å¯ç”¨")

        logger.info("RAGæœåŠ¡åˆå§‹åŒ–å®Œæˆ")
    
    def search_and_summarize(
        self,
        query: str,
        top_k: int = 10,
        filters: Optional[Dict] = None
    ) -> Dict:
        """
        æ£€ç´¢ + LLMæ€»ç»“
        
        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            top_k: æ£€ç´¢TOP Kä¸ªç»“æœ
            filters: è¿‡æ»¤æ¡ä»¶
            
        Returns:
            {
                'retrieved_jobs': [...],  # æ£€ç´¢åˆ°çš„å²—ä½
                'summary': '...',         # LLMæ€»ç»“ï¼ˆå¦‚æœå¯ç”¨ï¼‰
                'query': '...'            # åŸå§‹æŸ¥è¯¢
            }
        """
        logger.info(f"æœç´¢æŸ¥è¯¢: {query}")
        
        # 1. å‘é‡æ£€ç´¢
        results = self.vector_db.search(query, top_k=top_k, filters=filters)
        
        # æå–å²—ä½ä¿¡æ¯
        retrieved_jobs = []
        if results['metadatas'] and results['metadatas'][0]:
            for i, meta in enumerate(results['metadatas'][0]):
                distance = results['distances'][0][i]
                # 1/(1+d) å°†ä»»æ„éè´Ÿè·ç¦»æ˜ å°„åˆ°(0,1]ï¼Œå…¼å®¹L2å’Œcosineä¸¤ç§åº¦é‡
                similarity = round(1 / (1 + max(0, distance)), 3)
                
                # è§£ææŠ€èƒ½åˆ—è¡¨ï¼ˆé€—å·åˆ†éš”å­—ç¬¦ä¸² â†’ listï¼‰
                skills_raw = meta.get('skills', '')
                skills = [s.strip() for s in skills_raw.split(',') if s.strip()] if skills_raw else []

                job_info = {
                    'job_id': meta['job_id'],
                    'title': meta['title'],
                    'city': meta['city'],
                    'company': meta['company'],
                    'salary_range': f"{meta['salary_min']}-{meta['salary_max']}K",
                    'experience': meta.get('experience', ''),
                    'education': meta.get('education', ''),
                    'skills': skills,
                    'similarity': round(similarity, 3),
                    'document': results['documents'][0][i][:800]  # æ–‡æ¡£ç‰‡æ®µ
                }
                retrieved_jobs.append(job_info)
        
        # 2. Qwen API ç”Ÿæˆæ‘˜è¦
        summary = None
        if retrieved_jobs and self.qwen_api and self.qwen_api.api_key:
            try:
                summary = self._summarize_jobs(query, retrieved_jobs)
            except Exception as e:
                logger.warning(f"æ‘˜è¦ç”Ÿæˆå¤±è´¥: {e}")
                summary = None
        
        return {
            'retrieved_jobs': retrieved_jobs,
            'summary': summary,
            'query': query,
            'count': len(retrieved_jobs)
        }
    
    def _summarize_jobs(self, query: str, jobs: List[Dict]) -> str:
        """
        LLM æ€»ç»“æ£€ç´¢ç»“æœï¼ˆæœ¬åœ°æ¨¡å‹ä¼˜å…ˆï¼Œä¸å¯ç”¨è‡ªåŠ¨åˆ‡æ¢ Qwen APIï¼‰

        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            jobs:  æ£€ç´¢åˆ°çš„å²—ä½åˆ—è¡¨

        Returns:
            æ€»ç»“æ–‡æœ¬
        """
        # æ„å»ºä¸Šä¸‹æ–‡ï¼ˆæœ€å¤šå–å‰5ä¸ªå²—ä½ï¼‰
        context_jobs = []
        for i, job in enumerate(jobs[:5]):
            skills_str = 'ã€'.join(job.get('skills', [])[:6]) or 'æœªçŸ¥'
            context_jobs.append(
                f"{i+1}. {job['title']} â€” {job.get('company', 'ä¼ä¸š')}\n"
                f"   åŸå¸‚ï¼š{job.get('city', 'æœªçŸ¥')}  è–ªèµ„ï¼š{job.get('salary_range', 'é¢è®®')}"
                f"  ç»éªŒï¼š{job.get('experience', 'ä¸é™')}\n"
                f"   æŠ€èƒ½è¦æ±‚ï¼š{skills_str}"
            )
        context = "\n\n".join(context_jobs)

        prompt = f"""ç”¨æˆ·æŸ¥è¯¢ï¼š{query}

ç›¸å…³å²—ä½ï¼ˆå…± {len(jobs)} ä¸ªï¼Œå±•ç¤ºå‰5ä¸ªï¼‰ï¼š
{context}

è¯·ç”¨3-4å¥è¯ç®€æ´æ€»ç»“ï¼š
1. è¯¥ç±»å²—ä½çš„æ ¸å¿ƒæŠ€èƒ½è¦æ±‚
2. è–ªèµ„è¡Œæƒ…å’Œç«äº‰ç¨‹åº¦
3. ç»™æ±‚èŒè€…çš„ä¸€å¥å»ºè®®

ç›´æ¥è¾“å‡ºæ€»ç»“å†…å®¹ï¼Œä¸è¦åºå·å’Œæ ‡é¢˜ã€‚"""

        messages = [{"role": "user", "content": prompt}]
        return self.qwen_api.chat(messages, temperature=0.3, max_tokens=300)
    
    def skill_gap_analysis(
        self,
        user_skills: List[str],
        target_position: str,
        city: Optional[str] = None
    ) -> Dict:
        """
        æŠ€èƒ½å·®è·åˆ†æ
        
        Args:
            user_skills: ç”¨æˆ·å½“å‰æŠ€èƒ½
            target_position: ç›®æ ‡å²—ä½
            city: åŸå¸‚ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            {
                'analysis': '...',        # å·®è·åˆ†æ
                'target_jobs': [...],     # ç›®æ ‡å²—ä½æ ·æœ¬
                'required_skills': [...], # æ¨èå­¦ä¹ çš„æŠ€èƒ½
            }
        """
        logger.info(f"æŠ€èƒ½å·®è·åˆ†æ: {user_skills} -> {target_position}")
        
        # 1. æ£€ç´¢ç›®æ ‡å²—ä½
        query = f"{target_position} å²—ä½éœ€è¦çš„æŠ€èƒ½"
        filters = {"city": city} if city else None
        
        results = self.vector_db.search(query, top_k=20, filters=filters)
        
        # æå–å²—ä½ä¿¡æ¯
        target_jobs = []
        if results['metadatas'] and results['metadatas'][0]:
            for meta in results['metadatas'][0][:5]:
                target_jobs.append({
                    'title': meta['title'],
                    'city': meta['city'],
                    'company': meta['company'],
                    'salary_range': f"{meta['salary_min']}-{meta['salary_max']}K"
                })
        
        # 2. Qwen API åˆ†æå·®è·
        analysis = None
        if self.qwen_api and self.qwen_api.api_key:
            try:
                user_skills_str = 'ã€'.join(user_skills) if user_skills else 'ï¼ˆæœªæä¾›ï¼‰'
                prompt = f"""è¯·åˆ†æä»¥ä¸‹æŠ€èƒ½å·®è·æƒ…å†µï¼š

ç”¨æˆ·å½“å‰æŠ€èƒ½ï¼š{user_skills_str}
ç›®æ ‡å²—ä½ï¼š{target_position}

è¯·æä¾›ï¼š
1. ç”¨æˆ·å·²å…·å¤‡çš„ç›¸å…³æŠ€èƒ½
2. ç›®æ ‡å²—ä½é€šå¸¸è¦æ±‚ä½†ç”¨æˆ·å°šç¼ºçš„æŠ€èƒ½
3. å»ºè®®çš„å­¦ä¹ ä¼˜å…ˆçº§ï¼ˆé«˜/ä¸­/ä½ï¼‰
4. ç®€è¦çš„å­¦ä¹ è·¯å¾„å»ºè®®

è¯·ç”¨ç®€æ´ã€ç»“æ„åŒ–çš„æ–¹å¼å›ç­”ã€‚"""
                messages = [{"role": "user", "content": prompt}]
                analysis = self.qwen_api.chat(messages, temperature=0.3, max_tokens=600)
            except Exception as e:
                logger.warning(f"æŠ€èƒ½å·®è·åˆ†æå¤±è´¥: {e}")
                analysis = None
        
        return {
            'analysis': analysis,
            'target_jobs': target_jobs,
            'user_skills': user_skills,
            'target_position': target_position
        }
    
    def recommend_jobs(
        self,
        user_skills: List[str],
        top_k: int = 10,
        filters: Optional[Dict] = None
    ) -> Dict:
        """
        åŸºäºç”¨æˆ·æŠ€èƒ½æ¨èå²—ä½
        
        Args:
            user_skills: ç”¨æˆ·æŠ€èƒ½åˆ—è¡¨
            top_k: æ¨èTOP Kä¸ªå²—ä½
            filters: è¿‡æ»¤æ¡ä»¶
            
        Returns:
            æ¨èç»“æœ
        """
        logger.info(f"å²—ä½æ¨è: {user_skills}")
        
        # æ„å»ºæŸ¥è¯¢
        query = f"éœ€è¦ä»¥ä¸‹æŠ€èƒ½çš„å²—ä½: {', '.join(user_skills)}"
        
        # æ£€ç´¢
        return self.search_and_summarize(query, top_k=top_k, filters=filters)
    
    def find_similar_jobs(
        self,
        job_id: str,
        top_k: int = 5
    ) -> List[Dict]:
        """
        æŸ¥æ‰¾ç›¸ä¼¼å²—ä½
        
        Args:
            job_id: å²—ä½ID
            top_k: è¿”å›TOP Kä¸ªç›¸ä¼¼å²—ä½
            
        Returns:
            ç›¸ä¼¼å²—ä½åˆ—è¡¨
        """
        # è·å–åŸå²—ä½ä¿¡æ¯
        try:
            original_job = self.vector_db.collection.get(ids=[job_id])
            if not original_job['documents']:
                return []
            
            # ä½¿ç”¨åŸå²—ä½çš„æ–‡æ¡£ä½œä¸ºæŸ¥è¯¢
            query_doc = original_job['documents'][0]
            
            # æ£€ç´¢
            results = self.vector_db.search(query_doc, top_k=top_k+1)
            
            # è¿‡æ»¤æ‰åŸå²—ä½æœ¬èº«
            similar_jobs = []
            for i, meta in enumerate(results['metadatas'][0]):
                if meta['job_id'] != job_id:
                    similar_jobs.append({
                        'job_id': meta['job_id'],
                        'title': meta['title'],
                        'city': meta['city'],
                        'similarity': round(1 / (1 + max(0, results['distances'][0][i])), 3)
                    })
            
            return similar_jobs[:top_k]
            
        except Exception as e:
            logger.error(f"æŸ¥æ‰¾ç›¸ä¼¼å²—ä½å¤±è´¥: {e}")
            return []


# æµ‹è¯•ä»£ç 
def test_rag_service():
    """æµ‹è¯•RAGæœåŠ¡"""
    print("="*80)
    print("æµ‹è¯•RAGæœåŠ¡")
    print("="*80)
    
    # åˆå§‹åŒ–
    print("\nã€åˆå§‹åŒ–RAGæœåŠ¡ã€‘")
    rag = RAGService()
    print("âœ… åˆå§‹åŒ–æˆåŠŸ")
    
    # æµ‹è¯•1: è¯­ä¹‰æœç´¢+æ€»ç»“
    print("\nã€æµ‹è¯•1: è¯­ä¹‰æœç´¢+æ€»ç»“ã€‘")
    query = "Pythonåç«¯å¼€å‘ï¼Œç†Ÿæ‚‰Djangoå’ŒMySQL"
    result = rag.search_and_summarize(query, top_k=5)
    
    print(f"æŸ¥è¯¢: {query}")
    print(f"æ‰¾åˆ° {result['count']} ä¸ªç›¸å…³å²—ä½:")
    for job in result['retrieved_jobs'][:3]:
        print(f"  - {job['title']} | {job['city']} | {job['salary_range']} (ç›¸ä¼¼åº¦: {job['similarity']})")
    
    if result['summary']:
        print(f"\nLLMæ€»ç»“:")
        print(result['summary'][:200] + "...")
    
    # æµ‹è¯•2: æŠ€èƒ½å·®è·åˆ†æ
    print("\nã€æµ‹è¯•2: æŠ€èƒ½å·®è·åˆ†æã€‘")
    gap_result = rag.skill_gap_analysis(
        user_skills=["Python", "Django", "MySQL"],
        target_position="é«˜çº§Pythonåç«¯å·¥ç¨‹å¸ˆ"
    )
    
    print(f"ç”¨æˆ·æŠ€èƒ½: {gap_result['user_skills']}")
    print(f"ç›®æ ‡å²—ä½: {gap_result['target_position']}")
    print(f"æ‰¾åˆ° {len(gap_result['target_jobs'])} ä¸ªç›®æ ‡å²—ä½æ ·æœ¬")
    
    if gap_result['analysis']:
        print(f"\nå·®è·åˆ†æ:")
        print(gap_result['analysis'][:200] + "...")
    
    # æµ‹è¯•3: å²—ä½æ¨è
    print("\nã€æµ‹è¯•3: å²—ä½æ¨èã€‘")
    recommend_result = rag.recommend_jobs(
        user_skills=["Java", "Spring Boot", "MySQL"],
        top_k=5
    )
    
    print(f"æ¨è {recommend_result['count']} ä¸ªå²—ä½:")
    for job in recommend_result['retrieved_jobs'][:3]:
        print(f"  - {job['title']} | {job['city']}")
    
    print("\n" + "="*80)
    print("ğŸ‰ æµ‹è¯•å®Œæˆï¼")
    print("="*80)


if __name__ == "__main__":
    import logging
    
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    test_rag_service()
